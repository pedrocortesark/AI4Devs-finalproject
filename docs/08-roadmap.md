# FASE 8: Roadmap de Implementaci√≥n T√©cnica

**Documento**: Roadmap T√©cnico - Sagrada Familia Parts Manager  
**Versi√≥n**: 1.0  
**Fecha**: 28 de Enero de 2026  
**Autor**: Tech Lead - AI4Devs Team  

---

## üìã Tabla de Contenidos

1. [Visi√≥n General del Roadmap](#visi√≥n-general-del-roadmap)
2. [Sprint 0: Walking Skeleton](#sprint-0-walking-skeleton)
3. [Sprint 1: The Core (Ingesta)](#sprint-1-the-core-ingesta)
4. [Sprint 2: The Librarian (Agente)](#sprint-2-the-librarian-agente)
5. [Sprint 3: The Viewer (Visualizaci√≥n)](#sprint-3-the-viewer-visualizaci√≥n)
6. [Definition of Done (DoD)](#definition-of-done-dod)
7. [Estrategia de Testing](#estrategia-de-testing)
8. [M√©tricas de Progreso](#m√©tricas-de-progreso)

---

## Visi√≥n General del Roadmap

### Objetivo
Transformar la documentaci√≥n t√©cnica (Fases 1-7) en un sistema funcional desplegable en **4 Sprints incrementales** de 2 semanas cada uno, siguiendo la filosof√≠a de **"Working Software over Comprehensive Documentation"**.

### Principios de Implementaci√≥n
1. **Incremental Value**: Cada sprint entrega funcionalidad desplegable end-to-end.
2. **Risk First**: Los componentes m√°s cr√≠ticos y complejos se implementan primero (Walking Skeleton ‚Üí Agent ‚Üí Viewer).
3. **Testability**: Cada sprint incluye tests automatizados (unit + integration).
4. **Feedback Loops**: Deploy a staging al finalizar cada sprint para validaci√≥n temprana.

### Stack Tecnol√≥gico (Confirmado)
- **Backend**: FastAPI (Python 3.11+), Poetry, Pydantic v2
- **Frontend**: React 18, TypeScript, Vite, TanStack Query, Zustand
- **Agent**: LangGraph, LangChain, OpenAI GPT-4, rhino3dm (Python, lee formatos v5-v8, escribe v8)
- **Database**: Supabase (PostgreSQL + Storage + Auth)
- **3D Rendering**: Three.js (r160+), React Three Fiber, GLB format
- **Infrastructure**: Docker Compose (dev), Docker (prod), GitHub Actions (CI/CD)
- **Monitoring**: Sentry (errors), Supabase Analytics

---

## Sprint 0: Walking Skeleton
**Duraci√≥n**: 2 semanas  
**Goal**: Infraestructura desplegable con conectividad probada entre todos los componentes (Frontend ‚Üí Backend ‚Üí Database ‚Üí Agent).

### üéØ Objetivos
Implementar el "esqueleto andante" del sistema: una arquitectura m√≠nima funcional que conecte todos los componentes sin l√≥gica de negocio real. Esto permite validar la configuraci√≥n de infraestructura antes de a√±adir complejidad.

### üì¶ Entregables

#### 1. **Setup de Repositorio**
- [ ] Crear estructura de carpetas del monorepo (backend/, frontend/, agent/, shared/)
- [ ] Configurar `.gitignore` multi-proyecto (Python, Node, IDE, Docker)
- [ ] Configurar `.editorconfig` y `.prettierrc` para consistencia de c√≥digo
- [ ] Configurar GitHub Actions workflows (lint, test, build)

#### 2. **Backend - FastAPI Base**
- [ ] Inicializar proyecto Poetry (`pyproject.toml`)
  - Dependencias: `fastapi`, `uvicorn`, `supabase`, `pydantic`, `python-dotenv`
- [ ] Crear `app/main.py` con FastAPI app base
- [ ] Configurar CORS middleware
- [ ] Implementar health check endpoint: `GET /health`
  ```json
  {
    "status": "ok",
    "service": "sagrada-familia-backend",
    "version": "0.1.0",
    "timestamp": "2026-01-28T10:00:00Z"
  }
  ```
- [ ] Crear `app/config.py` para variables de entorno
- [ ] Configurar logging estructurado (structlog)
- [ ] Crear Dockerfile multi-stage (dev + prod)

#### 3. **Frontend - React + Vite Base**
- [ ] Inicializar proyecto Vite con template React-TS
- [ ] Configurar `package.json` con scripts (dev, build, test, lint)
  - Dependencias: `react`, `react-dom`, `@tanstack/react-query`, `zustand`, `axios`
- [ ] Crear layout b√°sico (Header + Sidebar + Content)
- [ ] Implementar componente `HealthCheck.tsx` que llame a `/health`
- [ ] Configurar cliente API con Axios (`src/services/api.ts`)
- [ ] Configurar variables de entorno (`.env.example`)
- [ ] Crear Dockerfile con Nginx para servir build est√°tico

#### 4. **Agent - Python Worker Base**
- [ ] Inicializar proyecto Poetry independiente
  - Dependencias: `langgraph`, `langchain`, `openai`, `supabase`
- [ ] Crear `librarian/main.py` con funci√≥n dummy de validaci√≥n
- [ ] Implementar logging y error handling b√°sico
- [ ] Crear Dockerfile

#### 5. **Supabase - Setup Database**
- [ ] Crear proyecto en Supabase Cloud (o instancia local con Docker)
- [ ] Configurar autenticaci√≥n (deshabilitada temporalmente para MVP)
- [ ] Crear esquema inicial con tabla `health_check`:
  ```sql
  CREATE TABLE health_check (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    checked_at TIMESTAMPTZ DEFAULT NOW(),
    status TEXT NOT NULL
  );
  ```
- [ ] Configurar Storage bucket: `parts-uploads`
- [ ] Guardar credenciales en `.env` de cada servicio

#### 6. **Docker Compose - Orquestaci√≥n Local**
- [ ] Crear `docker-compose.yml` con servicios:
  - `backend` (puerto 8000)
  - `frontend` (puerto 5173)
  - `agent` (sin puerto, solo worker)
  - `supabase-db` (PostgreSQL local opcional)
- [ ] Crear `docker-compose.dev.yml` con hot-reload volumes
- [ ] Documentar comandos en `README.md`:
  ```bash
  docker-compose up --build
  ```

#### 7. **Testing End-to-End**
- [ ] Test manual: `curl http://localhost:8000/health`
- [ ] Test manual: Abrir `http://localhost:5173` y ver dashboard vac√≠o
- [ ] Test automatizado: Script que valide conectividad entre servicios
  ```bash
  ./infrastructure/scripts/test-connectivity.sh
  ```

### ‚úÖ Criterios de Aceptaci√≥n (DoD)
- [ ] `docker-compose up` levanta todos los servicios sin errores
- [ ] Frontend renderiza y llama al backend exitosamente
- [ ] Backend responde a `/health` con JSON v√°lido
- [ ] Backend se conecta a Supabase (consulta a `health_check` tabla)
- [ ] Agent puede ejecutar una tarea dummy y loguear resultado
- [ ] CI/CD pipeline pasa (lint + build)
- [ ] Documentaci√≥n actualizada en `README.md` con instrucciones de setup

### üõ†Ô∏è Tareas T√©cnicas Detalladas

#### Backend (Tareas)
1. `poetry init` y a√±adir dependencias base
2. Crear `app/main.py`:
   ```python
   from fastapi import FastAPI
   from app.config import settings
   
   app = FastAPI(title="SF Parts Manager API", version="0.1.0")
   
   @app.get("/health")
   async def health_check():
       return {"status": "ok", "service": "backend"}
   ```
3. Crear `app/config.py` usando `pydantic-settings`
4. Configurar cliente Supabase en `app/services/db_service.py`
5. Test: `pytest tests/test_health.py`

#### Frontend (Tareas)
1. `pnpm create vite frontend --template react-ts`
2. Instalar dependencias: `pnpm add @tanstack/react-query zustand axios`
3. Crear `src/services/api.ts`:
   ```typescript
   import axios from 'axios';
   
   export const api = axios.create({
     baseURL: import.meta.env.VITE_API_URL || 'http://localhost:8000'
   });
   ```
4. Crear componente `HealthCheck.tsx` con fetch a `/health`
5. Test: `pnpm test` (Vitest)

#### Agent (Tareas)
1. `poetry init` en `agent/`
2. Crear `librarian/main.py`:
   ```python
   from langgraph.graph import Graph
   
   def validate_dummy(state):
       return {"status": "validated"}
   
   graph = Graph()
   graph.add_node("validate", validate_dummy)
   ```
3. Test: `pytest tests/test_graph.py`

---

## Sprint 1: The Core (Ingesta)
**Duraci√≥n**: 2 semanas  
**Goal**: Implementar la funcionalidad completa de carga de archivos `.3dm`, extracci√≥n de metadata b√°sica, y almacenamiento en Supabase.

### üéØ Objetivos
Permitir que un usuario suba un archivo Rhino (`.3dm`), extraer su metadata (nombre de capas, cantidad de objetos), y almacenar tanto el archivo como los metadatos en Supabase. Esta es la funcionalidad core del sistema sin validaci√≥n inteligente a√∫n.

### üì¶ Entregables

#### 1. **Backend - Upload Endpoint**
- [ ] Crear endpoint `POST /api/v1/parts/upload`
  - Acepta `multipart/form-data` con archivo `.3dm`
  - Validaciones: tama√±o m√°ximo (500MB), extensi√≥n `.3dm`
  - Retorna ID de pieza creada y URL de archivo
- [ ] Implementar servicio `StorageService`:
  ```python
  async def upload_file(file: UploadFile) -> str:
      """Sube archivo a Supabase Storage y retorna URL p√∫blica."""
  ```
- [ ] Implementar servicio `GeometryService` (wrapper de `rhino3dm`):
  ```python
  def extract_metadata(file_path: str) -> dict:
      """Extrae metadata b√°sica del archivo .3dm sin cargar geometr√≠a completa."""
      # - Nombre de archivo
      # - Estructura de capas (nombres + validaci√≥n compliance ISO per layer)
      # - N√∫mero de objetos y GUIDs
      # - Dimensiones del bounding box
      # - Fecha de creaci√≥n (si est√° en metadata)
      # - User Strings / Atributos personalizados
      # - Materiales asignados
      # - Jerarqu√≠a de bloques (Block Definitions)
  ```
- [ ] Implementar modelo `Part` (SQLAlchemy/Pydantic):
  ```python
  class PartCreate(BaseModel):
      original_filename: str
      file_url: str
      metadata: dict
  
  class PartResponse(PartCreate):
      id: UUID
      status: Literal["uploaded", "validating", "validated", "rejected", "requires_manual_review"]
      created_at: datetime
  ```
- [ ] Guardar registro en tabla `parts` de Supabase
- [ ] Implementar error handling (archivo corrupto, timeout, etc.)

#### 2. **Frontend - Upload UI**
- [ ] Crear componente `UploadZone.tsx` (drag & drop)
  - Librer√≠a: `react-dropzone`
  - Indicador de progreso de subida
  - Preview de archivo seleccionado (nombre, tama√±o)
- [ ] Crear hook `useUpload.ts`:
  ```typescript
  const { upload, progress, error } = useUpload();
  
  const handleUpload = async (file: File) => {
    const result = await upload(file);
    // Actualiza store con nueva pieza
  };
  ```
- [ ] Integrar con `partsStore` (Zustand) para actualizar lista en tiempo real
- [ ] Mostrar notificaci√≥n de √©xito/error (componente `Toast`)
- [ ] Validaciones frontend: tama√±o de archivo, extensi√≥n

#### 3. **Database - Schema Parts**
- [ ] Crear migraci√≥n de Supabase:
  ```sql
  CREATE TABLE parts (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    original_filename TEXT NOT NULL,
    file_url TEXT NOT NULL,
    status TEXT NOT NULL DEFAULT 'uploaded',
    metadata JSONB,
    created_at TIMESTAMPTZ DEFAULT NOW(),
    updated_at TIMESTAMPTZ DEFAULT NOW()
  );
  
  CREATE INDEX idx_parts_status ON parts(status);
  CREATE INDEX idx_parts_created_at ON parts(created_at DESC);
  ```
- [ ] Configurar Storage bucket policies (p√∫blico para lectura, autenticado para escritura)

#### 4. **Backend - List Parts Endpoint**
- [ ] Crear endpoint `GET /api/v1/parts`
  - Paginaci√≥n: `?page=1&limit=20`
  - Filtros: `?status=uploaded`
  - Ordenamiento: `?sort=created_at:desc`
  - Retorna lista de piezas con metadata resumida

#### 5. **Frontend - Parts List View**
- [ ] Crear componente `PartsList.tsx` (tabla o grid)
- [ ] Mostrar:
  - Nombre de archivo
  - Estado (badge con color)
  - Fecha de subida
  - N√∫mero de objetos (desde metadata)
- [ ] Implementar paginaci√≥n
- [ ] Implementar filtro por estado

#### 6. **Testing**
- [ ] **Backend**:
  - Test unitario: `test_extract_metadata()` con archivo `.3dm` de prueba
  - Test integraci√≥n: `test_upload_endpoint()` con mock de Supabase
- [ ] **Frontend**:
  - Test unitario: `UploadZone.test.tsx` simula drag & drop
  - Test E2E (Playwright): Subir archivo y verificar que aparece en lista

### ‚úÖ Criterios de Aceptaci√≥n (DoD)
- [ ] Usuario puede arrastrar un archivo `.3dm` a la UI
- [ ] Archivo se sube a Supabase Storage correctamente
- [ ] Metadata se extrae y guarda en tabla `parts`
- [ ] Lista de piezas muestra el archivo reci√©n subido
- [ ] Endpoint `/api/v1/parts` retorna datos paginados
- [ ] Tests automatizados pasan (coverage >80%)
- [ ] Documentaci√≥n API actualizada (OpenAPI/Swagger)

### üõ†Ô∏è Tareas T√©cnicas Detalladas

#### Backend (Estimaciones)
| Tarea | Horas | Responsable |
|-------|-------|-------------|
| Implementar `StorageService` | 4h | Backend Dev |
| Implementar `GeometryService` (rhino3dm) | 8h | Backend Dev |
| Crear endpoint `/upload` | 4h | Backend Dev |
| Crear endpoint `/parts` (list) | 3h | Backend Dev |
| Tests unitarios + integraci√≥n | 6h | Backend Dev |
| **TOTAL** | **25h** | |

#### Frontend (Estimaciones)
| Tarea | Horas | Responsable |
|-------|-------|-------------|
| Componente `UploadZone` | 5h | Frontend Dev |
| Hook `useUpload` | 3h | Frontend Dev |
| Componente `PartsList` | 4h | Frontend Dev |
| Integraci√≥n Zustand store | 2h | Frontend Dev |
| Tests E2E (Playwright) | 4h | Frontend Dev |
| **TOTAL** | **18h** | |

---

## Sprint 2: The Librarian (Agente)
**Duraci√≥n**: 2 semanas  
**Goal**: Integrar el agente de validaci√≥n inteligente basado en LangGraph. Las piezas subidas deben pasar por validaci√≥n autom√°tica.

### üéØ Objetivos
Implementar el componente m√°s diferenciador del sistema: **The Librarian**. El agente debe procesar archivos subidos, validar nomenclaturas seg√∫n ISO-19650, analizar geometr√≠a, y enriquecer metadatos usando LLMs. El resultado es un cambio de estado de la pieza: `uploaded` ‚Üí `validated` o `rejected`.

### üì¶ Entregables

#### 1. **Agent - LangGraph Implementation**
- [ ] Dise√±ar grafo de estados seg√∫n `docs/07-agent-design.md`
- [ ] Implementar nodos del grafo:
  - **Node 1: Metadata Validation** (`metadata_validation.py`)
    - Verifica que existan campos obligatorios
    - Valida formato de nombres de capas
  - **Node 2: Nomenclature Check** (`nomenclature_check.py`)
    - Aplica reglas ISO-19650 (regex)
    - Llama a LLM para validaci√≥n sem√°ntica de nombres
    - System Prompt:
      ```
      You are an ISO-19650 compliance validator for the Sagrada Familia construction project.
      
      Task: Validate if the layer name follows ISO-19650 naming conventions. 
      CRITICAL: You must strictly follow the Regex pattern. If there is a conflict between Regex and semantics, Regex wins.
      
      Layer name: {layer_name}
      
      Rules:
      1. Must follow Regex pattern: ^SF-[A-Z0-9]{3}-[A-Z]{3}-\d{3}$ (e.g., SF-NAV-COL-001)
      2. Building codes: SF-NAV (Nave), SF-FAC (Fachada), SF-TOR (Torre)
      3. Element codes: DOV (Dovela), BLO (Bloque), COL (Columna)
      
      Return JSON:
      {
        "valid": true/false,
        "error_message": "...",
        "suggested_fix": "..." 
      }
      ```
  - **Node 3: Geometry Analysis** (`geometry_analysis.py`)
    - Carga archivo `.3dm` con `rhino3dm`
    - Extrae volumen, dimensiones, n√∫mero de v√©rtices
    - Valida que geometr√≠a no est√© corrupta
  - **Node 4: Enrichment** (`enrichment.py`)
    - Llama a LLM para clasificar tipolog√≠a (Piedra/Hormig√≥n/Metal)
    - Infiere peso estimado basado en volumen y material
    - System Prompt:
      ```
      You are a construction materials expert for the Sagrada Familia.
      
      Task: Classify this architectural element and estimate its properties.
      
      Metadata:
      - Layer name: {layer_name}
      - Volume: {volume_m3} m¬≥
      - Dimensions: {width} x {height} x {depth} cm
      
      Return JSON:
      {
        "tipologia": "PIEDRA" | "HORMIGON" | "METAL",
        "peso_estimado_kg": 1500,
        "material_especifico": "Piedra de Montju√Øc",
        "confidence": 0.95
      }
      ```
  - **Node 5: Final Verdict** (`final_verdict.py`)
    - Compila resultados de nodos anteriores
    - Decide estado final: `validated` o `rejected`
    - Genera report JSON con detalles de validaci√≥n

- [ ] Implementar state management:
  ```python
  from typing import TypedDict, Literal
  
  class ValidationState(TypedDict):
      part_id: str
      file_path: str
      metadata: dict
      nomenclature_valid: bool
      geometry_valid: bool
      enriched_data: dict
      errors: list[str]
      final_status: Literal["validated", "rejected"]
  ```

- [ ] Implementar `graph/builder.py`:
  ```python
  from langgraph.graph import StateGraph
  
  def build_validation_graph():
      graph = StateGraph(ValidationState)
      
      graph.add_node("metadata_validation", metadata_validation_node)
      graph.add_node("nomenclature_check", nomenclature_check_node)
      graph.add_node("geometry_analysis", geometry_analysis_node)
      graph.add_node("enrichment", enrichment_node)
      graph.add_node("final_verdict", final_verdict_node)
      
      # Edges condicionales
      graph.add_conditional_edges(
          "metadata_validation",
          lambda state: "nomenclature_check" if state["metadata"] else "final_verdict"
      )
      
      graph.set_entry_point("metadata_validation")
      graph.set_finish_point("final_verdict")
      
      return graph.compile()
  ```

#### 2. **Backend - Integration con Agent**
- [ ] Crear endpoint `POST /api/v1/validation/trigger`
  - Recibe `part_id`
  - Encola tarea de validaci√≥n (Redis Queue o similar)
  - Retorna `job_id`
- [ ] Implementar `AgentService` (`services/agent_service.py`):
  ```python
  async def trigger_validation(part_id: UUID) -> str:
      """Encola tarea de validaci√≥n para el agente."""
      job = queue.enqueue('librarian.main.validate_part', part_id)
      return job.id
  ```
- [ ] Implementar worker que ejecuta el grafo:
  ```python
  # agent/workers/validation_worker.py
  def validate_part(part_id: str):
      # 1. Descargar archivo .3dm desde Supabase Storage
      # 2. Ejecutar grafo LangGraph
      # 3. Actualizar estado en DB con resultado
      # 4. Guardar report en Storage
  ```
- [ ] Crear tabla `validation_events` para audit trail:
  ```sql
  CREATE TABLE validation_events (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    part_id UUID REFERENCES parts(id),
    event_type TEXT NOT NULL,
    details JSONB,
    created_at TIMESTAMPTZ DEFAULT NOW()
  );
  ```

#### 3. **Frontend - Validation Status UI**
- [ ] A√±adir badge de estado en `PartCard.tsx`:
  - `uploaded`: Badge azul
  - `validating`: Badge amarillo (spinner)
  - `validated`: Badge verde (checkmark)
  - `rejected`: Badge rojo (X)
- [ ] Crear componente `ValidationReport.tsx`:
  - Muestra detalles del reporte de validaci√≥n
  - Errores encontrados
  - Sugerencias de correcci√≥n
  - Datos enriquecidos (tipolog√≠a, peso)
- [ ] Implementar polling o WebSocket para actualizar estado en tiempo real

#### 4. **Agent - Error Handling**
- [ ] Implementar retry logic para llamadas a LLM (max 3 intentos)
- [ ] Timeouts: 60s por nodo
- [ ] Fallback: Si LLM falla, marcar como `requires_manual_review`
- [ ] Logging estructurado con contexto (part_id, node_name, timestamp)

#### 5. **Testing**
- [ ] **Agent**:
  - Test unitario de cada nodo con estado mock
  - Test integraci√≥n: Ejecutar grafo completo con archivo `.3dm` de prueba
  - Test de manejo de errores (archivo corrupto, LLM timeout)
- [ ] **Backend**:
  - Test endpoint `/validation/trigger`
  - Mock de agent service

### ‚úÖ Criterios de Aceptaci√≥n (DoD)
- [ ] Al subir un archivo, se dispara validaci√≥n autom√°ticamente
- [ ] Agente procesa archivo y actualiza estado en DB
- [ ] Frontend muestra estado de validaci√≥n en tiempo real
- [ ] Report de validaci√≥n es accesible desde UI
- [ ] Piezas rechazadas muestran raz√≥n espec√≠fica
- [ ] Tests de integraci√≥n pasan (grafo completo)
- [ ] Agent maneja errores sin crashear

### üõ†Ô∏è Tareas T√©cnicas Detalladas

#### Agent (Estimaciones)
| Tarea | Horas | Responsable |
|-------|-------|-------------|
| Implementar grafo LangGraph | 12h | AI Engineer |
| Nodo 1: Metadata Validation | 4h | AI Engineer |
| Nodo 2: Nomenclature Check (LLM) | 6h | AI Engineer |
| Nodo 3: Geometry Analysis (rhino3dm) | 8h | AI Engineer |
| Nodo 4: Enrichment (LLM) | 6h | AI Engineer |
| Nodo 5: Final Verdict | 3h | AI Engineer |
| Error handling + retry logic | 5h | AI Engineer |
| Tests unitarios + integraci√≥n | 8h | AI Engineer |
| **TOTAL** | **52h** | |

#### Backend (Estimaciones)
| Tarea | Horas | Responsable |
|-------|-------|-------------|
| Endpoint `/validation/trigger` | 3h | Backend Dev |
| Integraci√≥n con queue (Redis/RQ) | 4h | Backend Dev |
| Worker implementation | 5h | Backend Dev |
| Tabla `validation_events` | 2h | Backend Dev |
| Tests | 4h | Backend Dev |
| **TOTAL** | **18h** | |

---

## Sprint 3: The Viewer (Visualizaci√≥n)
**Duraci√≥n**: 2 semanas  
**Goal**: Implementar el visor 3D interactivo con Three.js para visualizar piezas individuales y conjunto completo.

### üéØ Objetivos
Permitir que usuarios visualicen modelos 3D de piezas directamente en el navegador. Incluye conversi√≥n de `.3dm` a `.glb` (formato optimizado), renderizado con Three.js usando instancing para alto rendimiento, y controles de c√°mara (orbit, zoom, pan).

### üì¶ Entregables

#### 1. **Backend - Conversi√≥n 3DM ‚Üí GLB**
- [ ] Implementar servicio de conversi√≥n geom√©trica:
  ```python
  # app/services/geometry_converter.py
  async def convert_3dm_to_glb(input_path: str, output_path: str):
      """
      Convierte archivo .3dm a .glb usando rhino3dm.
      
      Research & Prototyping Tasks:
      - Evaluar viabilidad de conversi√≥n directa rhino3dm -> glb
      - Benchmark de librer√≠as de compresi√≥n Draco
      - Definir estrategia LOD (Level of Detail) para modelos arquitect√≥nicos
      - Performance benchmarks vs tama√±o de archivo
      
      Optimizaciones:
      - Reducci√≥n de pol√≠gonos (LOD)
      - Compresi√≥n Draco
      - Tama√±o m√°ximo: 10MB
      """
  ```
- [ ] Ejecutar conversi√≥n como tarea as√≠ncrona (Celery/RQ)
- [ ] Almacenar `.glb` en Supabase Storage:
  - Bucket: `parts-glb`
  - Estructura: `{part_id}/model.glb`
- [ ] A√±adir campo `glb_url` a tabla `parts`
- [ ] Crear endpoint `GET /api/v1/parts/{id}/preview`
  - Retorna URL del archivo `.glb`

#### 2. **Frontend - Three.js Viewer**
- [ ] Instalar dependencias:
  ```bash
  pnpm add three @react-three/fiber @react-three/drei
  ```
- [ ] Crear componente `ThreeViewer.tsx`:
  ```typescript
  interface ThreeViewerProps {
    modelUrl: string;
    enableControls?: boolean;
    backgroundColor?: string;
  }
  
  export const ThreeViewer: React.FC<ThreeViewerProps> = ({
    modelUrl,
    enableControls = true,
    backgroundColor = '#f0f0f0'
  }) => {
    return (
      <Canvas camera={{ position: [5, 5, 5], fov: 50 }}>
        <ambientLight intensity={0.5} />
        <directionalLight position={[10, 10, 5]} intensity={1} />
        <Suspense fallback={<Loader />}>
          <GLBModel url={modelUrl} />
        </Suspense>
        {enableControls && <OrbitControls />}
      </Canvas>
    );
  };
  ```
- [ ] Crear componente `GLBModel.tsx`:
  ```typescript
  import { useGLTF } from '@react-three/drei';
  
  export const GLBModel = ({ url }: { url: string }) => {
    const { scene } = useGLTF(url);
    return <primitive object={scene} />;
  };
  ```
- [ ] A√±adir controles:
  - Orbit (rotar con mouse)
  - Zoom (rueda del mouse)
  - Pan (click derecho + arrastrar)
  - Reset c√°mara (bot√≥n)

#### 3. **Frontend - Part Detail View**
- [ ] Crear vista `PartDetailPage.tsx`:
  - Header con nombre de pieza y estado
  - Visor 3D (ocupa 70% del viewport)
  - Panel lateral con metadata:
    - Tipolog√≠a
    - Dimensiones
    - Peso estimado
    - Estado de validaci√≥n
    - Bot√≥n "Descargar .3dm original"
- [ ] Integrar con router:
  ```typescript
  <Route path="/parts/:id" element={<PartDetailPage />} />
  ```

#### 4. **Frontend - Instanced Scene Viewer (Bonus)**
- [ ] Crear vista de conjunto (opcional para MVP):
  - Renderiza m√∫ltiples piezas simult√°neamente
  - Usa `InstancedMesh` de Three.js para optimizar rendimiento
  - Permite seleccionar pieza individual (raycast)

#### 5. **Backend - Batch Conversion**
- [ ] Crear script para convertir piezas existentes:
  ```bash
  python scripts/batch_convert.py --status=validated
  ```
- [ ] Progress tracking en DB (tabla `conversion_jobs`)

#### 6. **Testing**
- [ ] **Backend**:
  - Test unitario: `test_convert_3dm_to_glb()` con archivo de prueba
  - Validar que `.glb` generado es v√°lido
- [ ] **Frontend**:
  - Test visual: Screenshot testing con Playwright
  - Test de rendimiento: Medir FPS con 100+ piezas instanciadas

### ‚úÖ Criterios de Aceptaci√≥n (DoD)
- [ ] Usuario puede hacer clic en una pieza y ver modelo 3D
- [ ] Visor carga `.glb` en <3 segundos
- [ ] Controles de c√°mara funcionan correctamente
- [ ] Conversi√≥n `.3dm` ‚Üí `.glb` se ejecuta autom√°ticamente
- [ ] Metadata se muestra junto al visor
- [ ] Visor funciona en Chrome, Firefox, Safari
- [ ] Performance >30 FPS con modelos de 5MB

### üõ†Ô∏è Tareas T√©cnicas Detalladas

#### Backend (Estimaciones)
| Tarea | Horas | Responsable |
|-------|-------|-------------|
| Implementar `geometry_converter.py` | 10h | Backend Dev |
| Configurar Celery para conversi√≥n async | 4h | Backend Dev |
| Endpoint `/preview` | 2h | Backend Dev |
| Batch conversion script | 3h | Backend Dev |
| Tests | 4h | Backend Dev |
| **TOTAL** | **23h** | |

#### Frontend (Estimaciones)
| Tarea | Horas | Responsable |
|-------|-------|-------------|
| Componente `ThreeViewer` | 8h | Frontend Dev |
| Componente `GLBModel` + loader | 4h | Frontend Dev |
| Controles de c√°mara | 3h | Frontend Dev |
| Vista `PartDetailPage` | 5h | Frontend Dev |
| Integraci√≥n con API | 3h | Frontend Dev |
| Performance optimization | 4h | Frontend Dev |
| Tests (screenshot + E2E) | 4h | Frontend Dev |
| **TOTAL** | **31h** | |

---

## Definition of Done (DoD)

### Para Cada Sprint
- [ ] **Funcional**: Todas las historias de usuario est√°n implementadas y funcionando
- [ ] **Testeable**: Tests automatizados pasan (coverage m√≠nimo 80%)
- [ ] **Documentado**: README actualizado con nuevas instrucciones
- [ ] **Deployable**: Puede desplegarse a staging sin errores
- [ ] **Revisado**: Code review aprobado por al menos 1 reviewer
- [ ] **Memoria Actualizada**: Memory Bank actualizado (systemPatterns.md, progress.md, decisions.md)

### Para Todo el Proyecto (Final Sprint 3)
- [ ] **Performance**: Backend responde <500ms (P95)
- [ ] **Performance**: Frontend carga inicial <2s
- [ ] **Security**: Variables sensibles en `.env` (no hardcoded)
- [ ] **Monitoring**: Sentry configurado y enviando eventos
- [ ] **CI/CD**: GitHub Actions ejecuta tests en cada PR
- [ ] **Documentaci√≥n T√©cnica**: OpenAPI/Swagger actualizado
- [ ] **Documentaci√≥n Usuario**: Manual de uso b√°sico

---

## Estrategia de Testing

### Pir√°mide de Testing
```
       /\
      /  \  E2E Tests (10%)
     /----\ Integration Tests (30%)
    /------\ Unit Tests (60%)
```

### Por Capa

#### Backend
- **Unit Tests** (pytest):
  - Servicios (StorageService, GeometryService)
  - Validadores (ISO-19650 regex)
  - Conversi√≥n `.3dm` ‚Üí metadata
- **Integration Tests** (pytest + testcontainers):
  - Endpoints API con DB real (PostgreSQL test instance)
  - Supabase Storage (mock o test bucket)
- **E2E Tests** (Playwright):
  - Flow completo: Upload ‚Üí Validaci√≥n ‚Üí Visualizaci√≥n

#### Frontend
- **Unit Tests** (Vitest):
  - Componentes aislados (UploadZone, PartCard)
  - Hooks (useUpload, useParts)
  - Utilidades (formatters, validators)
- **Integration Tests** (React Testing Library):
  - Flujos de usuario (subir archivo, ver lista)
- **Visual Tests** (Playwright + Percy):
  - Screenshots de visor 3D
  - Regression visual en componentes

#### Agent
- **Unit Tests** (pytest):
  - Cada nodo del grafo de forma aislada
  - Tools (iso_validator, geometry_analyzer)
- **Integration Tests**:
  - Grafo completo con archivo `.3dm` de prueba
  - Manejo de errores (LLM timeout, archivo corrupto)

### Fixtures de Prueba
- Archivo `.3dm` de prueba (10MB, geometr√≠a simple)
- Archivo `.3dm` corrupto (para tests de error handling)
- Archivo `.3dm` grande (500MB, para tests de performance)

---

## M√©tricas de Progreso

### M√©tricas T√©cnicas
| M√©trica | Sprint 0 | Sprint 1 | Sprint 2 | Sprint 3 |
|---------|----------|----------|----------|----------|
| **API Endpoints** | 1 | 4 | 6 | 8 |
| **Test Coverage (Backend)** | 50% | 70% | 80% | 85% |
| **Test Coverage (Frontend)** | 40% | 65% | 75% | 80% |
| **Agent Nodes** | 0 | 0 | 5 | 5 |
| **DB Tables** | 1 | 3 | 5 | 6 |
| **Docker Services** | 3 | 3 | 4 | 4 |

### M√©tricas de Valor
| M√©trica | Sprint 0 | Sprint 1 | Sprint 2 | Sprint 3 |
|---------|----------|----------|----------|----------|
| **User Stories Completadas** | 1 | 3 | 5 | 8 |
| **% Funcionalidad Core** | 10% | 40% | 80% | 100% |
| **Piezas Procesadas (Demo)** | 0 | 10 | 50 | 100 |

### Burn-Down Chart (Horas Estimadas + 20% Contingencia)
```
Sprint 0: 72h (Setup + Buffer)
Sprint 1: 96h (Core Features + Buffer)
Sprint 2: 120h (Agent Implementation + Buffer)
Sprint 3: 96h (Visualization + Buffer)
---
TOTAL: 384h (~2.5 meses con equipo de 2-3 devs)
```

---

## Notas Finales

### Riesgos Identificados
1. **Rhino3dm Performance**: Conversi√≥n de archivos grandes puede ser lenta.
   - **Mitigaci√≥n**: Implementar queue y procesamiento as√≠ncrono desde Sprint 1.
2. **LLM Costs**: Llamadas a GPT-4 pueden ser costosas con alto volumen.
   - **Mitigaci√≥n**: Cachear resultados de validaci√≥n, usar GPT-3.5 donde sea posible.
3. **Three.js Performance**: Renderizar 1000+ piezas puede saturar GPU.
   - **Mitigaci√≥n**: Implementar LOD (Level of Detail) y culling agresivo.

### Dependencias Externas
- **Supabase Cloud**: Requiere cuenta y proyecto configurado antes de Sprint 0.
- **OpenAI API Key**: Necesaria para Sprint 2 (agent).
- **Rhino3dm Library**: Validar compatibilidad con versiones recientes de archivos `.3dm`.

### Pr√≥ximos Pasos (Post-Sprint 3)
- **Autenticaci√≥n**: Integrar Supabase Auth (roles: Admin, Architect, Worker).
- **Notificaciones**: WebSockets para updates en tiempo real.
- **Reporting**: Dashboards con m√©tricas de producci√≥n (piezas validadas/d√≠a).
- **Mobile**: Versi√≥n responsive optimizada para tablets en taller.

---

**Fin del Roadmap T√©cnico - Listo para Sprint 0** üöÄ
