# System Patterns

## Architecture
The system relies on a **Memory Bank** architecture where state is explicitly documented in Markdown files.

### Monorepo Structure
```text
src/
├── backend/      # FastAPI service (Python 3.11+)
├── frontend/     # React 18 + TypeScript + Vite
├── agent/        # LangGraph agent (future)
└── shared/       # Shared utilities
```

## Core Components
- **Memory Bank**: `/memory-bank/` (State storage)
- **Agent Rules**: `/.agent/rules/` (Behavior enforcement)
- **Backend API**: FastAPI with Pydantic schemas
- **Frontend**: React SPA with TypeScript strict mode
- **Storage**: Supabase Storage for file uploads

## API Contract Patterns

### Frontend-Backend Interface Alignment
**Critical Pattern**: TypeScript interfaces MUST match Pydantic schemas exactly to avoid runtime errors.

#### Upload Flow Contract (T-002-BACK ↔ T-003-FRONT)

**Backend Schema** (`src/backend/schemas.py`):
```python
class UploadRequest(BaseModel):
    filename: str
    size: int
    checksum: Optional[str]

class UploadResponse(BaseModel):
    upload_url: str
    file_id: str      # ← UUID generated by backend
    filename: str     # ← Echo of original filename
```

**Frontend Interface** (`src/frontend/src/types/upload.ts`):
```typescript
interface PresignedUrlRequest {
  filename: string;
  size: number;
  checksum?: string;
}

interface PresignedUrlResponse {
  upload_url: string;
  file_id: string;    // ← Matches backend
  filename: string;   // ← Matches backend
}
```

**Historical Note**: Initial implementation used `file_key` instead of `file_id`, which caused test failures. Fixed in prompt #040 to align with backend reality.

#### Validation Report Contract (T-020-DB ↔ T-023-TEST)

**Backend Schema** (`src/backend/schemas.py`):
```python
class ValidationErrorItem(BaseModel):
    category: str
    target: Optional[str]
    message: str

class ValidationReport(BaseModel):
    is_valid: bool
    errors: List[ValidationErrorItem]
    metadata: Dict[str, Any]
    validated_at: Optional[datetime]
    validated_by: Optional[str]
```

**Frontend Interface** (`src/frontend/src/types/validation.ts`):
```typescript
interface ValidationErrorItem {
  category: string;
  target?: string;
  message: string;
}

interface ValidationReport {
  is_valid: boolean;
  errors: ValidationErrorItem[];
  metadata: Record<string, any>;
  validated_at?: string;  // ISO datetime string
  validated_by?: string;
}
```

**Usage Context**: This contract supports async validation of .3dm files by "The Librarian" agent (T-024-AGENT). `ValidationReport` is stored as JSONB in `blocks.validation_report` column (T-020-DB) and displayed in frontend validation UI (T-032-FRONT).

**Design Decisions**:
- `category`: Error types ("nomenclature", "geometry", "io") for grouping/filtering
- `target`: Optional identifier (layer name, object ID) for error localization
- `metadata`: Flexible schema for extracted Rhino user strings and layer info
- `validated_at`: Timestamp for audit trail and debugging
- `validated_by`: Worker identifier for troubleshooting distributed validation

## Backend Architecture Patterns

### Clean Architecture (Implemented in T-004-BACK)
**Pattern**: Separation of Concerns with three-layer architecture.

**Structure**:
```text
src/backend/
├── api/              # API Layer (Controllers)
│   └── upload.py     # Endpoints, request/response handling only
├── services/         # Business Logic Layer
│   └── upload_service.py  # Core business logic
├── constants.py      # Centralized configuration
└── schemas.py        # Pydantic models (DTOs)
```

**Responsibilities**:
- **API Layer** (`api/`): HTTP handling, validation delegation, error mapping
- **Service Layer** (`services/`): Business logic, orchestration, data persistence
- **Constants** (`constants.py`): All magic strings/numbers centralized

**Example** (`T-004-BACK` - Confirm Upload):
```python
# api/upload.py (thin controller)
@router.post("/confirm")
async def confirm_upload(request: ConfirmUploadRequest):
    upload_service = UploadService(supabase_client)
    success, event_id, error = upload_service.confirm_upload(...)
    if not success:
        raise HTTPException(...)
    return ConfirmUploadResponse(event_id=event_id)

# services/upload_service.py (business logic)
class UploadService:
    def confirm_upload(self, file_id, file_key):
        # 1. Verify file in storage
        # 2. Create event record
        # 3. Return result tuple
        ...
```

**Benefits**:
- Testable: Services can be unit tested without HTTP layer
- Reusable: Business logic accessible from CLI/workers/API
- Maintainable: Changes to business rules don't affect routing

### Constants Centralization
**Pattern**: All hardcoded values in `src/backend/constants.py`.

```python
# constants.py
STORAGE_BUCKET_RAW_UPLOADS = "raw-uploads"
EVENT_TYPE_UPLOAD_CONFIRMED = "upload.confirmed"
TABLE_EVENTS = "events"
ALLOWED_EXTENSION = ".3dm"
MAX_FILE_SIZE_MB = 500
```

**Enforcement**: Router and services MUST import from constants, never hardcode strings.

### Testing Patterns
- **Backend**: pytest with integration tests for Supabase Storage
- **Frontend**: Vitest + @testing-library/react
  - **Docker Environment**: node:20-bookworm (Debian) required for jsdom stability
  - **Issue**: Alpine Linux (musl) causes fatal JavaScript memory errors with jsdom
  - **Solution**: Use glibc-based images (Debian/Ubuntu) for frontend testing

## Frontend Architecture Patterns

### Component Organization (Implemented in T-001-FRONT)
**Pattern**: Separation of Concerns with constants extraction (mirrors backend pattern).

**Structure**:
```text
src/frontend/src/components/
├── UploadZone.tsx            # Component logic (presentation + behavior)
├── UploadZone.constants.ts   # Centralized configuration
└── UploadZone.test.tsx       # Test suite
```

**Responsibilities**:
- **Component** (`.tsx`): React component logic, hooks, JSX rendering
- **Constants** (`.constants.ts`): Configuration values, styles, error messages, helpers
- **Tests** (`.test.tsx`): Component behavior verification

### Constants Extraction Pattern
**Pattern**: Extract all magic values to dedicated constants file (same as backend).

**Example** (`T-001-FRONT` - UploadZone):
```typescript
// UploadZone.constants.ts
export const UPLOAD_ZONE_DEFAULTS = {
  MAX_FILE_SIZE: 500 * 1024 * 1024,  // 500MB
  ACCEPTED_MIME_TYPES: ['application/x-rhino', 'application/octet-stream'],
  ACCEPTED_EXTENSIONS: ['.3dm'],
} as const;

export const ERROR_MESSAGES = {
  FILE_TOO_LARGE: (maxSizeMB: number) => 
    `File is too large. Maximum size is ${maxSizeMB}MB.`,
  INVALID_FILE_TYPE: (extensions: string[]) => 
    `Invalid file type. Only ${extensions.join(', ')} files are accepted.`,
  TOO_MANY_FILES: 'Only one file can be uploaded at a time.',
  INVALID_FILE_OBJECT: 'Invalid file object.',
} as const;

export const CLASS_NAMES = {
  CONTAINER: 'upload-zone-container',
  DROPZONE: 'upload-zone',
  ACTIVE: 'upload-zone--active',
  DISABLED: 'upload-zone--disabled',
  ERROR: 'upload-zone--error',
  ERROR_MESSAGE: 'upload-zone-error',
} as const;

export const STYLES = {
  dropzone: {
    base: { border: '2px dashed #ccc', borderRadius: '8px', ... },
    idle: { backgroundColor: '#fafafa', borderColor: '#ccc', ... },
    active: { backgroundColor: '#f0f8ff', borderColor: '#4299e1', ... },
    error: { backgroundColor: '#fff5f5', borderColor: '#fc8181', ... },
    disabled: { opacity: 0.5, cursor: 'not-allowed' },
  },
  message: {
    active: { margin: 0, color: '#4299e1', fontWeight: 500 },
    idle: {
      primary: { margin: '0 0 8px 0', fontSize: '16px', color: '#2d3748' },
      secondary: { margin: 0, fontSize: '14px', color: '#718096' },
    },
  },
  error: {
    container: { marginTop: '12px', padding: '12px 16px', ... },
  },
} as const;

// Helper functions
export function formatSizeInMB(bytes: number): number {
  return Math.round(bytes / (1024 * 1024));
}

export function buildDropzoneStyles(isDragActive, hasError, isDisabled) {
  // Compute styles based on state
}
```

**Usage in Component**:
```typescript
// UploadZone.tsx
import {
  UPLOAD_ZONE_DEFAULTS,
  ERROR_MESSAGES,
  CLASS_NAMES,
  STYLES,
  formatSizeInMB,
  buildDropzoneStyles,
} from './UploadZone.constants';

export function UploadZone({ maxFileSize = UPLOAD_ZONE_DEFAULTS.MAX_FILE_SIZE }) {
  const handleError = () => {
    setErrorMessage(ERROR_MESSAGES.FILE_TOO_LARGE(formatSizeInMB(maxFileSize)));
  };
  
  return (
    <div className={CLASS_NAMES.CONTAINER}>
      <div className={CLASS_NAMES.DROPZONE} style={buildDropzoneStyles(...)}>
        {/* ... */}
      </div>
    </div>
  );
}
```

**Benefits**:
- **Maintainability**: Change config in one place (e.g., 500MB → 1GB)
- **Consistency**: Error messages use same templates everywhere
- **Testability**: Constants importable in tests for validation
- **Reduced Complexity**: Component logic separated from configuration
- **Type Safety**: `as const` ensures immutability and better inference

**Historical Note**: Original implementation (Prompt #059) had 206 lines with inline styles/config. Refactored to 160 lines in Prompt #060 (22% reduction) by extracting 127-line constants file.

## Agent (Celery Worker) Architecture Patterns

### Agent Module Structure (Implemented in T-022-INFRA)
**Pattern**: Clean Architecture with constants centralization (consistent with backend/frontend).

**Structure**:
```text
src/agent/
├── celery_app.py       # Celery instance configuration
├── config.py           # Environment-based settings (Pydantic)
├── constants.py        # Centralized configuration values
├── tasks.py            # Celery task definitions
├── requirements.txt    # Dependencies
└── Dockerfile          # Multi-stage build (dev/prod)
```

**Responsibilities**:
- **celery_app.py**: Initialize Celery app, configure broker/backend, import tasks
- **config.py**: Environment variables validation (CELERY_BROKER_URL, DATABASE_URL, etc.)
- **constants.py**: Task timeouts, retry policies, task names (immutable config)
- **tasks.py**: Business logic for async tasks (@celery_app.task decorators)

### Constants Centralization (Agent Specific)
**Pattern**: All timeout values, retry policies, and task names in `src/agent/constants.py`.

**Implementation** (`T-022-INFRA` Refactor):
```python
# constants.py
CELERY_APP_NAME = "sf_pm_agent"
TASK_TIME_LIMIT_SECONDS = 600  # 10min hard kill (.3dm files up to 500MB)
TASK_SOFT_TIME_LIMIT_SECONDS = 540  # 9min warning (allows cleanup)
WORKER_PREFETCH_MULTIPLIER = 1  # One task at a time (isolate large files)
RESULT_EXPIRES_SECONDS = 3600  # 1 hour auto-cleanup
TASK_MAX_RETRIES = 3
TASK_RETRY_DELAY_SECONDS = 60  # 1min between retries
TASK_HEALTH_CHECK = "agent.tasks.health_check"  # Type-safe task names
TASK_VALIDATE_FILE = "agent.tasks.validate_file"
```

**Usage**:
```python
# celery_app.py
from constants import TASK_TIME_LIMIT_SECONDS, WORKER_PREFETCH_MULTIPLIER

celery_app.conf.update(
    task_time_limit=TASK_TIME_LIMIT_SECONDS,
    worker_prefetch_multiplier=WORKER_PREFETCH_MULTIPLIER,
)

# tasks.py
from constants import TASK_HEALTH_CHECK, TASK_MAX_RETRIES, TASK_RETRY_DELAY_SECONDS

@celery_app.task(
    name=TASK_HEALTH_CHECK,
    max_retries=TASK_MAX_RETRIES,
    default_retry_delay=TASK_RETRY_DELAY_SECONDS
)
def health_check(self):
    ...
```

**Benefits**:
- **Consistency**: Same pattern as backend/frontend (team familiarity)
- **Maintainability**: Timeout adjustments in one place
- **Type Safety**: Task names as constants (refactoring support)
- **Testing**: Constants importable in tests for validation

**Conditional Imports Pattern**:
Agent modules support both direct execution (worker) and module imports (tests):
```python
# Support both /app execution and src.agent imports
try:
    import constants
    if hasattr(constants, 'CELERY_APP_NAME'):
        from constants import TASK_HEALTH_CHECK
    else:
        raise ImportError("Wrong constants module")  # Avoid backend/constants.py collision
except (ImportError, ModuleNotFoundError):
    from src.agent.constants import TASK_HEALTH_CHECK
```

## Folder Structure
```text
/memory-bank/   -> Documentation root
/.agent/rules/  -> Rules for AI agents
/src/           -> Source code (monorepo)
/docs/          -> Product documentation
/infra/         -> Infrastructure as code
/tests/         -> Integration tests
```

---

## User String Extraction Pattern (T-025-AGENT)

### Overview
Rhino .3dm files support embedding custom metadata as "User Strings" (key-value pairs) at three levels:
1. **Document-level**: Project metadata (e.g., `ProjectID`, `BIM_Manager`)
2. **Layer-level**: Manufacturing specs per layer (e.g., `Workshop`, `MaterialType`)
3. **Object-level**: Part-specific data (e.g., `ISO_Code`, `Mass`, `QA_Inspector`)

This pattern extracts and structures user strings for ISO-19650 compliance and manufacturing traceability.

### Data Model (`src/agent/models.py`)

**UserStringCollection** (Pydantic v2):
```python
from pydantic import BaseModel, ConfigDict, Field
from typing import Dict

class UserStringCollection(BaseModel):
    """Sparse dictionaries for user string metadata."""
    document: Dict[str, str] = Field(default_factory=dict)
    layers: Dict[str, Dict[str, str]] = Field(default_factory=dict)  # layer_name → strings
    objects: Dict[str, Dict[str, str]] = Field(default_factory=dict)  # object_uuid → strings
    
    model_config = ConfigDict(
        json_schema_extra={"example": {
            "document": {"ProjectID": "SF-2026", "BIM_Manager": "Pedro Cortés"},
            "layers": {"SF-C12-M-001": {"Workshop": "Granollers", "MaterialType": "UHPC"}},
            "objects": {"3f2504e0...": {"ISO_Code": "SF-C12-M-001", "Mass": "450kg"}}
        }}
    )
```

**FileProcessingResult** (updated):
```python
class FileProcessingResult(BaseModel):
    success: bool
    layers: List[LayerInfo]
    file_metadata: Dict[str, Any]
    user_strings: Optional[Dict[str, Any]] = None  # UserStringCollection as dict
    
    model_config = ConfigDict(from_attributes=True)
```

### Service Architecture

**UserStringExtractor** (`src/agent/services/user_string_extractor.py`):
- **Method**: `extract(model: File3dm) -> UserStringCollection`
- **Defensive patterns**:
  - `hasattr()` checks before accessing rhino3dm API properties
  - Per-item try-except (failures don't break entire extraction)
  - Graceful handling of `None` returns from `GetUserStrings()`
  - Sparse dictionaries (only include items with strings)
- **Logging**: Structured logs with context (`document_keys`, `layer_count`, `object_count`)

**Example Implementation**:
```python
def _extract_layer_strings(self, model) -> Dict[str, Dict[str, str]]:
    result = {}
    for layer in model.Layers:
        try:
            if not hasattr(layer, 'GetUserStrings'):
                continue
            strings_dict = layer.GetUserStrings()
            if strings_dict is None or not hasattr(strings_dict, 'Keys'):
                continue
            layer_strings = {key: strings_dict[key] for key in strings_dict.Keys}
            if layer_strings:  # Sparse: only add if has strings
                result[layer.Name] = layer_strings
        except Exception as e:
            logger.warning("layer_string_extraction_failed", layer=layer.Name, error=str(e))
            continue  # Don't break extraction for one bad layer
    return result
```

### Integration with RhinoParserService

**Location**: `src/agent/services/rhino_parser_service.py`
```python
# After extracting layers and file_metadata:
extractor = UserStringExtractor()
user_strings = extractor.extract(model)

return FileProcessingResult(
    success=True,
    layers=layers,
    file_metadata=file_metadata,
    user_strings=user_strings.model_dump()  # Convert to dict for Pydantic v2 compatibility
)
```

### Pydantic v2 Migration Note

**Issue**: Nested Pydantic models require `model_dump()` when passed to parent model constructors.
**Solution**: `UserStringCollection` is created in service, then serialized to `Dict[str, Any]` before assigning to `FileProcessingResult.user_strings`.
**Benefit**: Avoids Pydantic validation errors while maintaining type safety in service layer.

### Testing Strategy (TDD Complete)

**Unit Tests** (`tests/unit/test_user_string_extractor.py`): 8 tests
- Happy path: document, layer, object extraction
- Edge cases: empty strings, None returns, missing attributes
- Error handling: API exceptions, corrupt data

**Integration Tests** (`tests/integration/test_user_strings_e2e.py`): 3 tests
- E2E workflow: RhinoParserService → UserStringExtractor → FileProcessingResult
- Sparse object validation (only objects with strings in result)
- Empty file handling (empty dicts, not None)

**Results**: 11/11 PASS (2026-02-13), no regression in T-024-AGENT (6 passed, 4 skipped)

### rhino3dm API Quirks Documented

| API Method | Behavior | Defensive Strategy |
|------------|----------|-------------------|
| `model.Strings` | Can be missing in old .3dm versions | `hasattr()` check |
| `layer.GetUserStrings()` | Returns `None` if no strings | Explicit `None` check |
| `obj.Attributes.GetUserStrings()` | May throw `AttributeError` | Try-except wrapper |
| `NameValueDictionary.Keys` | Iterator (not list) | Convert to list/iterate directly |
| `obj.Attributes.Id` | Returns rhino3dm UUID object | Cast to `str()` for dict keys |

### Use Cases
1. **Sagrada Familia Project**: 46 user strings defined (ISO codes, materials, workshop assignments)
2. **ISO-19650 Compliance**: Document/layer metadata for audit trail
3. **Manufacturing Integration**: Object-level part numbers, QA notes, mass calculations
4. **Validation Rules**: Future nomenclature validation can reference extracted user strings

---
