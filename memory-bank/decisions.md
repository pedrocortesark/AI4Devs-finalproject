# Registro de Decisiones Arquitect√≥nicas y de Producto

Este archivo documenta todas las decisiones importantes tomadas durante el desarrollo del proyecto. Funciona como un ADR (Architecture Decision Record) simplificado.

## 2025-12-19 - Implementaci√≥n del Memory Bank
- **Contexto:** En un entorno multi-agente como Antigravity, m√∫ltiples instancias de Gemini pueden trabajar simult√°neamente en diferentes partes del c√≥digo. Sin un estado compartido, los agentes podr√≠an entrar en conflicto o perder contexto.
- **Decisi√≥n:** Crear una estructura de "Memory Bank" con archivos markdown que sirvan como fuente √∫nica de verdad para el contexto del proyecto. Implementar reglas obligatorias (`.agent/rules/00-memory-bank.md`) que fuercen a todos los agentes a leer el contexto antes de trabajar.
- **Consecuencias:** 
  - ‚úÖ **Ganamos:** Coherencia entre agentes, trazabilidad de cambios, contexto persistente.
  - ‚ö†Ô∏è **Perdemos:** Requiere disciplina para mantener actualizado, overhead inicial de documentaci√≥n.

---

## 2025-12-19 - Separaci√≥n del Market Analysis en Archivo Dedicado
- **Contexto:** La investigaci√≥n de mercado genera mucha informaci√≥n t√°ctica (pain points, competidores, propuestas). Incluirla en `productContext.md` lo har√≠a excesivamente largo y dif√≠cil de mantener.
- **Decisi√≥n:** Crear `memory-bank/market-analysis.md` como archivo dedicado para toda la investigaci√≥n de mercado y propuestas estrat√©gicas. Mantener `productContext.md` enfocado en el contexto de negocio de alto nivel.
- **Consecuencias:**
  - ‚úÖ **Ganamos:** Separaci√≥n de concerns, f√°cil navegaci√≥n, documentaci√≥n especializada.
  - ‚ö†Ô∏è **Perdemos:** Un archivo m√°s que mantener sincronizado.

---

## 2025-12-23 - Evaluaci√≥n de Smart XREF como Candidato TFM
- **Contexto:** El pain point de XREF/Large Model Management identificado en market research (7k views en Discourse) parec√≠a un candidato fuerte. Se requer√≠a validaci√≥n t√©cnica antes de comprometer 3 meses de TFM.
- **Decisi√≥n:** Realizar an√°lisis de viabilidad profundo antes de comenzar desarrollo. Crear `feasibility-smart-xref.md` con evaluaci√≥n cr√≠tica de: data gravity, limitaciones de rhino3dm, an√°lisis competitivo (Speckle), y estrategias de indexado.
- **Consecuencias:**
  - ‚úÖ **Ganamos:** Evitamos comprometer 3 meses en proyecto demasiado ambicioso. Descubrimos que la soluci√≥n completa (granular loading) requiere custom file parser y equipo de 12-18 meses.
  - ‚úÖ **Ganamos:** Identificamos MVP viable: metadata index (b√∫squeda sin carga granular) que es factible en 3 meses.
  - ‚ö†Ô∏è **Pendiente:** Decisi√≥n entre Smart XREF MVP (metadata index) o pivot a Semantic Rhino (clasificaci√≥n AI de capas).

---

## 2025-12-23 - Evaluaci√≥n T√©cnica: Deep Learning vs. Hybrid para Semantic Rhino
- **Contexto:** La propuesta original de Semantic Rhino suger√≠a usar PointNet/Graph CNNs (redes neuronales geom√©tricas). Se requer√≠a an√°lisis cr√≠tico de viabilidad t√©cnica para un TFM de 3 meses.
- **Decisi√≥n:** Rechazar enfoque de Deep Learning acad√©mico. Adoptar **arquitectura h√≠brida**: LLM (GPT-4/Gemini) para clasificaci√≥n zero-shot + algoritmos geom√©tricos cl√°sicos (bounding box, normales, volumen) para validaci√≥n.
- **Consecuencias:**
  - ‚úÖ **Ganamos:** 
    - No requiere dataset etiquetado (PointNet necesita 1,000+ ejemplos por clase)
    - Timeline realista (2-3 semanas vs. 8-10 semanas)
    - Accuracy aceptable (75-85% vs. 90-95% te√≥rico de DL)
    - Explainability (reglas transparentes vs. black box)
  - ‚ö†Ô∏è **Perdemos:** 
    - Menor "novedad acad√©mica" aparente
    - Dependencia de APIs externas (OpenAI/Google)
    - Costo operativo (~$5/d√≠a en API calls)
  - ‚úÖ **Justificaci√≥n Pragm√°tica:** GPT-4 logra 95% accuracy en clasificaci√≥n zero-shot sin entrenamiento. El objetivo es un producto funcional, no un paper de investigaci√≥n.

---

## 2025-12-24 - Rechazo de RL para SmartFabricator: Realidad de Taller
- **Contexto:** La propuesta original de SmartFabricator suger√≠a usar Reinforcement Learning para optimizaci√≥n multi-objetivo (precisi√≥n vs. coste vs. velocidad). Se requer√≠a "reality check" t√©cnico considerando limitaciones de hardware y seguridad.
- **Decisi√≥n:** **Rechazar** enfoque de Reinforcement Learning para TFM. **Condicionar** SmartFabricator solo como **Curve-to-Arc MVP** usando optimizaci√≥n cl√°sica + ML para predicci√≥n de tolerancia.
- **Consecuencias:**
  - ‚ùå **Por qu√© NO RL:**
    - Requiere simulador de CNC f√≠sicamente preciso (8+ semanas solo para el simulador)
    - Necesita 100k-1M iteraciones de entrenamiento (semanas en GPU)
    - **Cr√≠tico**: Sin acceso a CNC para validaci√≥n, todo es te√≥rico sin prueba de realidad
    - **Seguridad**: RL podr√≠a "alucinar" G-code peligroso (colisiones f√≠sicas, da√±o a m√°quinas)
  - ‚úÖ **Alternativa Viable (MVP Curve-to-Arc)**:
    - Usa optimizaci√≥n convexa cl√°sica (determinista, garant√≠as matem√°ticas)
    - ML solo para predicci√≥n de tolerancia √≥ptima (low-risk, high-value)
    - Output: Geometr√≠a DXF limpia (NO G-code) ‚Üí CAM software hace la conversi√≥n segura
    - Timeline: 12 semanas factibles
  - ‚ö†Ô∏è **Lecci√≥n Clave**: "El papel lo aguanta todo, pero el taller no perdona bad G-code." La fabricaci√≥n digital requiere validaci√≥n f√≠sica que no es viable en un TFM sin acceso a maquinaria industrial.

---

## 2025-12-26 - Rechazo de AEC Copilot para Producci√≥n: Ruleta Rusa Legal
- **Contexto:** La propuesta de AEC Interaction Copilot (Natural Language ‚Üí RhinoScript execution) promete UX revolucionario pero requiere ejecutar c√≥digo generado por LLM directamente en entorno de producci√≥n con archivos de $50k+.
- **Decisi√≥n:** **Aprobar SOLO como demo de investigaci√≥n educativa**. **Rechazar rotundamente como herramienta de producci√≥n** para usuarios reales sin infraestructura de seguridad empresarial.
- **Consecuencias:**
  - ‚ùå **Por qu√© NO Producci√≥n:**
    - **Alucinaci√≥n Destructiva**: LLM puede generar `rs.DeleteObjects(rs.AllObjects())` por error ‚Üí 40 horas de trabajo perdidas
    - **Sandbox Escapes**: Investigaci√≥n muestra que incluso contenedores Docker tienen vulnerabilidades explotables
    - **Prompt Injection**: Atacantes pueden manipular LLM para generar c√≥digo malicioso
    - **Responsabilidad Legal**: Una eliminaci√≥n accidental viral en Twitter = demanda que termina carrera
    - **Infraestructura Requerida**: Docker sandbox + security audit  + legal ToS = $20k+ y 6+ meses con equipo
  - ‚úÖ **Viable como Demo TFM**:
    - Dry-run preview mode (geometr√≠a temporal en capa preview)
    - Whitelist estricto (SOLO operaciones seguras, NO `rs.DeleteObjects()`)
    - Disclaimers educativos ("Research prototype only")
    - Thesis focus en arquitectura de seguridad
    - **Nota de TFM**: 8-9/10 (innovaci√≥n reconocida, scope limitado a investigaci√≥n aceptado)
  - **comparativa Industria**: GitHub Copilot (oro est√°ndar) tiene ej√©rcito de ingenieros de seguridad + disclaimers extensos + **NO auto-ejecuci√≥n** (usuario debe copiar-pegar c√≥digo). AEC Copilot propone ejecutar autom√°ticamente = gap de responsabilidad inaceptable.
  - ‚ö†Ô∏è **Lecci√≥n Clave**: "Natural Language + Code Execution = Ruleta Rusa Legal. Construye herramientas que los abogados no demandar√°n. Guarda esto para el PhD, no el TFM."

---

## 2025-12-26 - Rechazo de AEC-NeuralSync para TFM: Complejidad PhD + Riesgo de Privacidad Comprobado
- **Contexto:** La propuesta de AEC-NeuralSync (Federated Learning + LoRA Weights Exchange) promete un sistema revolucionario donde estudios de arquitectura entrenan modelos privados localmente y solo comparten pesos LoRA para mejorar un "Modelo Maestro". La hip√≥tesis clave era: "Los pesos LoRA no permiten reverse-engineering de los datos originales."
- **Decisi√≥n:** **Rechazar rotundamente** AEC-NeuralSync como opci√≥n TFM. **Condicionar** SOLO como tema de **PhD (3-5 a√±os)** o **startup post-TFM con financiaci√≥n ($500k+)**.
- **Consecuencias:**
  - ‚ùå **Claim de Privacidad DESMENTIDO por investigaci√≥n**:
    - **Membership Inference Attacks (MIA)**: √âxito >90% determinando si datos espec√≠ficos estuvieron en entrenamiento (LoRA-Leak framework)
    - **Reconstructi√≥n de Datos**: Posible extraer c√≥digo/im√°genes originales desde pesos compartidos (Diffusion Models 2024)
    - **Extracci√≥n de Modelos**: Replicar funcionalidad completa del adaptador LoRA
    - **Escenario Legal Real**: Estudio A entrena en fachadas propietarias ‚Üí Competidor B (tambi√©n cliente) ejecuta MIA ‚Üí Descubre patrones espec√≠ficos de A ‚Üí **Demanda por robo de IP** ‚Üí Startup muere
  - ‚ùå **4 Componentes Nivel-PhD Requeridos**:
    1. **Differential Privacy**: 8-12 semanas (gradient clipping + ruido gaussiano calibrado, matem√°tica avanzada)
    2. **LoRA Merging sin Catastrophic Forgetting**: 8-12 semanas (problema de investigaci√≥n activo 2024, sin garant√≠as)
    3. **Serializaci√≥n DAG-to-Sequence**: 4-6 semanas (Grasshopper es grafo, LLMs procesan texto secuencial)
    4. **Infraestructura Federated Learning**: 12-16 semanas (sistemas distribuidos complejos)
  - ‚ùå **Timeline Realista**: 40-60 semanas (18+ meses) vs. 3 meses TFM
  - ‚ùå **Probabilidad de √âxito TFM**: 10-20% (vs. 85% Semantic Rhino)
  - ‚ùå **Riesgo Legal Comprobado**: Si competidor extrae dise√±os propietarios desde pesos compartidos = demandas millonarias
  - ‚úÖ **Alcance Viable (SI se ignoran advertencias)**: 
    - **SOLO** RAG local (b√∫squeda sem√°ntica archivos .gh)
    - **SOLO** LoRA local single-client (NO merging, NO weights exchange)
    - **ABANDONAR** completamente federated learning y claims de privacidad
    - Tesis se convierte en: "Knowledge Base Local para Dise√±o Param√©trico" (factible 12 semanas)
  - ‚ö†Ô∏è **Comparativa con Industria**: 
    - Google Federated Learning: Equipos de 50+ investigadores PhD, a√±os de desarrollo
    - Apple Differential Privacy: Infraestructura masiva, presupuestos multi-mill√≥n
    - **Tu propuesta**: 1 estudiante, 3 meses, 0 financiaci√≥n ‚Üí **Scope mismatch extremo**
  - ‚ö†Ô∏è **Lecci√≥n Clave**: "Intentar construir Tesla Roadster cuando necesitas primero una bicicleta funcional. Semantic Rhino ES la bicicleta. AEC-NeuralSync es el Roadster. Construye la bicicleta, grad√∫ate, LUEGO levanta $10M para construir el Roadster."

---

## 2025-12-30 - Aprobaci√≥n Condicional de GH-Copilot: GitHub Copilot para Grasshopper con Backup Plan
- **Contexto:** GH-Copilot es la 6¬™ opci√≥n TFM. Propone un sistema de predicci√≥n de nodos en tiempo real para Grasshopper usando fine-tuning LoRA o RAG sobre biblioteca privada de archivos `.gh`. Es una variante "scoped-down" que evita los dos asesinos: ejecuci√≥n arbitraria de c√≥digo (AEC Copilot) y federated learning multi-cliente (AEC-NeuralSync).
- **Decisi√≥n:** **Aprobar CONDICIONAL** como opci√≥n TFM #2-3 (empate con SmartFabricator-MVP). **REQUIERE backup plan obligatorio**: Si serializaci√≥n DAG falla en Semana 6 ‚Üí pivot a Semantic Rhino.
- **Consecuencias:**
  - ‚úÖ **Evita Problemas Cr√≠ticos de Opciones Previas**:
    - **NO** ejecuci√≥n de c√≥digo (vs. AEC Copilot) ‚Üí Cero riesgo legal por `DeleteObjects()`
    - **NO** federated learning (vs. AEC-NeuralSync) ‚Üí Cero riesgo extracci√≥n IP entre competidores
    - **S√ç** entrenamiento local single-client ‚Üí Privacidad garantizada (datos nunca salen del servidor)
  - ‚úÖ **Propuesta de Valor Clara**: "GitHub Copilot para Grasshopper" (analog√≠a viral)
  - ‚úÖ **Probabilidad √âxito**: 70-75% (variante RAG), **superior** a AEC Copilot (10% producci√≥n) y AEC-NeuralSync (10-20%)
  - ‚ö†Ô∏è **CUELLO DE BOTELLA CR√çTICO**: **Calidad Serializaci√≥n DAG** (60% riesgo fallo)
    - Grasshopper usa Data Trees (`{0;1}`, `{0;2}`) y estructuras de grafo paralelas
    - Si serializaci√≥n pierde esta info ‚Üí modelo aprende basura ‚Üí precisi√≥n <50%
    - **Mitigaci√≥n**: Invertir 2-3 semanas extra en serializaci√≥n robusta con metadata de data trees
  - ‚úÖ **Recomendaciones T√©cnicas Mandatorias**:
    1. **Approach**: **RAG (NO LoRA)** para MVP
       - **Por qu√©**: 6 semanas m√°s r√°pido, funciona con datasets peque√±os (50+ .gh files OK)
       - **LoRA**: Requiere 500+ graphs, 2-4 horas entrenamiento GPU, riesgo overfitting
    2. **Serializaci√≥n**: **Pseudo-sintaxis** (`Point->Circle->Extrude`) mejor que JSON
       - **Por qu√©**: 70% menos tokens, LLM aprende patrones naturalmente
    3. **UX**: **Side Panel (NO Ghost Nodes)**
       - **Por qu√©**: Ghost Nodes requieren 6-8 semanas (hacking GH SDK internals, muy arriesgado)
       - Side Panel: 2-3 semanas, Eto.Forms est√°ndar, cero riesgo
    4. **Stack**:
       - Backend: Python (ChromaDB + Flask API)
       - Frontend: C# GH Plugin (Eto.Forms + HttpClient)
       - Parser: GH_IO.dll (mapeo GUID ‚Üí Component Type)
  - ‚ö†Ô∏è **Plan de Contingencia OBLIGATORIO**:
    - **Semana 6 Decision Gate**: Medir precisi√≥n retrieval/predicci√≥n
      - SI < 50% precisi√≥n ‚Üí **PIVOT INMEDIATO a Semantic Rhino** (no negociable)
      - SI 60%+ precisi√≥n ‚Üí Continuar con GH-Copilot
    - **Rational**: Evitar sunk-cost fallacy. Mejor cambiar a Semana 6 que entregar TFM incompleto Semana 12.
  - ‚úÖ **Comparativa Risk/Reward**:
    - **Semantic Rhino**: 85% √©xito, menor wow-factor, **M√ÅS SEGURO**
    - **GH-Copilot**: 70-75% √©xito, mayor wow-factor (viral en Twitter), **M√ÅS COOL PERO RIESGOSO**
  - ‚ö†Ô∏è **Lecci√≥n Clave**: "GH-Copilot es el √öNICO 'Copilot' variant achievable en 3 meses. Es GitHub Copilot scoped correctamente. Si falla DAG serialization, tienes Semantic Rhino como red de seguridad s√≥lida."

---

## 2026-01-13 - Aprobaci√≥n de Sagrada Familia Parts Manager: Opci√≥n Enterprise / Systems Architect
- **Contexto:** Surgi√≥ una 7¬™ opci√≥n enfocada en un caso real "Enterprise": Sistema de Gesti√≥n de Piezas para la Sagrada Familia. Se aleja de la idea de "producto SaaS" para enfocarse en "Soluci√≥n a Medida / Digital Twin".
- **Decisi√≥n:** **Aprobar como Opci√≥n Tier 1 (Empate con Semantic Rhino)**.
- **Consecuencias:**
  - ‚úÖ **Portfolio Value**: Posiciona el TFM como "Senior Systems Architect" (Full Stack + 3D + Cloud + Data).
  - ‚úÖ **Viabilidad**: Alta (90%). No hay riesgos "cient√≠ficos" (como RL o Serializaci√≥n de Grafos), solo retos de Ingenier√≠a (optimizaci√≥n 3D, concurrencia DB).
  - ‚úÖ **Diferenciaci√≥n**: Se compite por calidad de ejecuci√≥n, no por novedad algor√≠tmica.
  - ‚ö†Ô∏è **Trade-off**: Menos "AI Core" (LangGraph es potente pero no es un LLM entrenado desde cero).
  - ‚úÖ **Stack Recomendado**:
    - **Frontend**: React + Three.js (Instancing clave para performance).
    - **Backend**: Python (FastAPI + rhino3dm).
    - **Data**: PostgreSQL (Supabase) para RBAC y Relacional.
    - **AI**: LangChain/LangGraph para clasificaci√≥n autom√°tica (Agente "Librarian").
  - ‚ö†Ô∏è **Elecci√≥n de Carrera**:
    - Si el objetivo es **AI Engineer** puro ‚Üí **Semantic Rhino**.
    - Si el objetivo es **Tech Lead / Solutions Architect** ‚Üí **Sagrada Familia**.

---

## 2026-01-20 - SELECCI√ìN OFICIAL DE PROYECTO: Sagrada Familia Parts Manager
- **Contexto:** Tras analizar 7 opciones viable (desde algoritmos puros hasta herramientas SaaS), se debe elegir el proyecto √∫nico para el TFM del m√°ster ai4devs.
- **Decisi√≥n:** **Seleccionar "Sagrada Familia Parts Manager"** como el proyecto definitivo.
- **Alternativas Descartadas:**
  - *Semantic Rhino*: Excelente SaaS, pero enfocado m√°s en ML/Algoritmia pura. Menor componente de "Arquitectura de Sistemas".
  - *GH-Copilot*: Alto riesgo t√©cnico (DAG Serialization) y enfoque "Startup", menos alineado con perfil "Solutions Architect".
- **Justificaci√≥n:**
  1. **Alineaci√≥n Profesional**: Este proyecto demuestra habilidades de **Senior Systems Architect** (Full Stack + 3D + Data + AI Integration), un perfil altamente demandado en la industria moderna (Industry 4.0).
  2. **Caso de Uso Real**: Simular un cliente de patrimonio cr√≠tico (Sagrada Familia) fuerza decisiones de dise√±o m√°s robustas y realistas (Alta Disponibilidad, Data Integrity) que un "Toy Project".
  3. **AI Pragm√°tica**: Implementa Agentes (LangGraph) para tareas de "Limpieza y Clasificaci√≥n de Datos", un caso de uso de AI mucho m√°s implantable hoy en d√≠a que la generaci√≥n generativa pura en CAD.
- **Consecuencias:**
  - El TFM deja de ser una exploraci√≥n de startups.
  - El foco t√©cnico pasa a: **Optimizaci√≥n 3D (Three.js)**, **Integraci√≥n Rhino3dm Backend**, y **Agentes de Orquestaci√≥n**.
  - Se cierra la fase de "Ideaci√≥n" y comienza "Definici√≥n de Producto (PRD)".

---

## 2026-01-26 - Kickoff Oficial: README como Single Source of Truth T√©cnico
- **Contexto:** Con el proyecto oficializado (Sagrada Familia Parts Manager), necesitamos centralizar toda la especificaci√≥n t√©cnica en un documento maestro que sirva como:
  1. Referencia arquitect√≥nica completa para desarrollo
  2. Documentaci√≥n t√©cnica para presentaci√≥n a inversores/stakeholders
  3. Gu√≠a de implementaci√≥n para el roadmap MVP
- **Decisi√≥n:** Crear **README.md** como documento centralizado conteniendo:
  - Arquitectura completa del sistema (Frontend/Backend/Data/AI)
  - Stack tecnol√≥gico definitivo con justificaci√≥n de cada elecci√≥n
  - Modelo de datos PostgreSQL detallado
  - Roadmap de features priorizado por valor de negocio (P0-MVP ‚Üí P1-Scale ‚Üí P2-Enterprise)
  - User personas extendidas con pain points espec√≠ficos de Oficina T√©cnica SF
- **Justificaci√≥n del Enfoque Architecture & Systems**:
  - **Portfolio Value**: Demuestra capacidad Senior Systems Architect (vs. SaaS/Startup scope m√°s limitado)
  - **Viabilidad Controlada**: 90% probabilidad √©xito (vs. 70-75% GH-Copilot con riesgo serializaci√≥n DAG)
  - **Impacto Real**: Simula delivery cliente enterprise cr√≠tico (patrimonio UNESCO) forzando decisiones de dise√±o robustas
  - **AI Pragm√°tica**: Agentes para validaci√≥n/clasificaci√≥n datos (alta implantabilidad) vs. generaci√≥n c√≥digo (alta aleatoriedad)
- **Consecuencias:**
  - ‚úÖ **Ganamos:**
    - Documentaci√≥n viva que evoluciona con el c√≥digo
    - Claridad arquitect√≥nica desde semana 1 (evita re-arquitecturas tard√≠as)
    - Material de presentaci√≥n t√©cnica directamente reutilizable
    - Decisiones t√©cnicas trackeadas en mismo documento (monorepo, storage, async processing)
  - ‚úÖ **Estrategia MVP para Inversores:**
    - P0 (Semanas 1-6): Upload + Validation + 3D Viewer ‚Üí **Demo funcional presentable**
    - P1 (Semanas 7-9): Search + RBAC + Audit ‚Üí **Escalabilidad enterprise**
    - P2 (Semanas 10-12): API + Integraciones ‚Üí **Extensibilidad ecosistema**
  - ‚ö†Ô∏è **Trade-offs:**
    - README extenso (estimado 800-1200 l√≠neas) requiere disciplina de actualizaci√≥n
    - Riesgo de "documentaci√≥n adelantada al c√≥digo" si no se sincroniza
  - ‚úÖ **Mitigaci√≥n:** Protocolo AGENTS.md obliga actualizar systemPatterns.md/techContext.md ante cambios arquitect√≥nicos
- **Decisiones T√©cnicas Bloqueantes Identificadas (Requieren Resoluci√≥n Semana 1):**
  1. **Estructura Monorepo**: Turborepo vs. Nx vs. monorepo simple con workspaces
  2. **Storage Archivos Pesados**: Git LFS vs. Supabase Storage vs. AWS S3 (an√°lisis costo/latencia)
  3. **Async Processing**: Celery+Redis vs. BullMQ vs. Temporal (complejidad setup vs. features)
  4. **Autenticaci√≥n**: Supabase Auth (integrado) vs. JWT custom (control total)
  5. **Testing Strategy**: Jest+Pytest vs. Vitest+Pytest (velocidad vs. compatibilidad)

---

## 2026-02-09 - Adopci√≥n de Clean Architecture para Backend (T-004-BACK Refactor)
- **Contexto:** El c√≥digo de T-0004-BACK ten√≠a toda la l√≥gica de negocio (verificaci√≥n de storage, creaci√≥n de eventos) mezclada directamente en el endpoint del router. Esto viola el principio de Separation of Concerns y hace dif√≠cil:
  - Unit testing de l√≥gica de negocio sin levantar servidor HTTP
  - Reutilizar l√≥gica desde workers/CLI/otros contextos
  - Mantener y evolucionar c√≥digo a medida que crece el proyecto
- **Decisi√≥n:** Refactorizar backend siguiendo **Clean Architecture con tres capas**:
  1. **API Layer (`api/`)**: Solo manejo de HTTP (routing, validation, error mapping)
  2. **Service Layer (`services/`)**: Toda la l√≥gica de negocio y orquestaci√≥n
  3. **Constants (`constants.py`)**: Centralizaci√≥n de magic strings/numbers
- **Implementaci√≥n Concreta**:
  - Creado `src/backend/services/upload_service.py` con clase `UploadService`
  - Extra√≠dos m√©todos: `verify_file_exists_in_storage()`, `create_upload_event()`, `confirm_upload()`
  - Creado `src/backend/constants.py` con: `STORAGE_BUCKET_RAW_UPLOADS`, `EVENT_TYPE_UPLOAD_CONFIRMED`, `TABLE_EVENTS`, `ALLOWED_EXTENSION`
  - Reducido endpoint `/confirm` a 15 l√≠neas (coordinaci√≥n HTTP solamente)
- **Consecuencias:**
  - ‚úÖ **Ganamos:**
    - **Testabilidad**: Servicios probables sin HTTP layer (unit tests aislados)
    - **Reusabilidad**: L√≥gica accesible desde Celery workers, CLI tools, otros endpoints
    - **Mantenibilidad**: Cambios de reglas de negocio no afectan routing
    - **Escalabilidad**: Patr√≥n replicable para todas las features futuras (T-001-BACK, etc.)
    - **Code Review**: Funciones peque√±as, responsabilidades claras  
  - ‚ö†Ô∏è **Trade-offs**:
    - M√°s archivos (complejidad aparente inicial para proyecto peque√±o)
    - Requiere disciplina para no volver a mezclar l√≥gica en routers
  - ‚úÖ **Validaci√≥n**: 7/7 tests siguen pasando post-refactor (verificaci√≥n anti-regresi√≥n exitosa)
- **Enforcement Going Forward**: 
  - Todo nuevo endpoint DEBE seguir este patr√≥n
  - Code review rechazar√° l√≥gica de negocio en routers
  - `systemPatterns.md` actualizado con ejemplos y gu√≠as

---

## 2026-02-09 - Mejora del Proceso de Logging con Snippets de Espanso
- **Contexto:** Durante auditor√≠a de codebase (prompt #048), se detect√≥ que el prompt original fue registrado como `:audit-master` (trigger de espanso) en lugar del texto expandido completo. Esto genera p√©rdida de contexto en prompts.md, violando el principio de trazabilidad completa del proyecto.
- **Root Cause:** AGENTS.md no ten√≠a regla espec√≠fica sobre c√≥mo manejar snippets de text expansion. El AI intent√≥ "adivinar" si era un snippet pero registr√≥ el formato incorrecto.
- **Decisi√≥n:** Estandarizar el manejo de snippets de espanso en el workflow de logging:
  1. **Regla en AGENTS.md**: AI DEBE registrar SIEMPRE el texto expandido completo que ve en userRequest, NUNCA solo el trigger
  2. **Formato Est√°ndar** para snippets:
     ```markdown
     **Prompt Original (Snippet expandido):**
     > :trigger-name
     >
     > [Texto completo expandido del snippet]
     ```
  3. **Gu√≠a de Best Practices**: Crear `.github/AI-BEST-PRACTICES.md` con patrones para:
     - Uso correcto de snippets en prompts
     - Workflow TDD (RED ‚Üí GREEN ‚Üí REFACTOR)
     - Validaci√≥n de cambios
     - Memory Bank management
     - Auditor√≠as peri√≥dicas
     - Troubleshooting
- **Implementaci√≥n**:
  - ‚úÖ Actualizado AGENTS.md secci√≥n 1.B con nota "IMPORTANTE - Snippets de Espanso"
  - ‚úÖ Creado `.github/AI-BEST-PRACTICES.md` (335 l√≠neas, 10 secciones)
  - ‚úÖ Actualizado README.md con secci√≥n "Desarrollo Asistido por IA" referenciando gu√≠as
  - ‚úÖ Corregido prompt #048 con texto expandido completo
- **Consecuencias:**
  - ‚úÖ **Ganamos:**
    - **Trazabilidad completa**: Prompts registrados con contexto completo
    - **Onboarding mejorado**: Nuevos colaboradores/agentes pueden seguir best practices documentadas
    - **Menos errores de proceso**: Reglas claras reducen ambig√ºedad
    - **Escalabilidad del workflow**: Gu√≠a replicable para otros proyectos
  - ‚ö†Ô∏è **Trade-offs**:
    - Requiere que usuario informe al AI si detecta errores de registro
    - Documentaci√≥n adicional a mantener
  - ‚úÖ **Validaci√≥n**: Formato de prompt #048 corregido y verificado
- **Enforcement Going Forward**:
  - AI verificar√° presencia de triggers (`:nombre`) y registrar√° texto completo
  - Usuario puede usar formato de nota expl√≠cita cuando use snippets complejos
  - Code review de prompts.md verificar√° que entradas tengan contexto completo

---

## 2026-02-14 - Exclusi√≥n de Tests Backend del Pipeline Agent
- **Contexto:** Durante T-028-BACK (Validation Report Service), se cre√≥ `tests/unit/test_validation_report_service.py` (test de backend) en el directorio `tests/unit/` que tambi√©n contiene tests de agent. El comando `make test-agent` ejecuta TODOS los tests en `tests/unit/` dentro del contenedor `agent-worker`, causando fallo de pipeline CI/CD porque ese contenedor no tiene dependencias de backend (`src/backend/services`, `src/backend/schemas`).
- **Decisi√≥n:** **Short-term fix:** Modificar Makefile para que `make test-agent` excluya expl√≠citamente `test_validation_report_service.py` usando `--ignore=tests/unit/test_validation_report_service.py`. **Long-term debt:** Refactorizar estructura de tests a `tests/backend/unit/` y `tests/agent/unit/` (Clean Architecture).
- **Consecuencias:**
  - ‚úÖ **Ganamos:**
    - Pipeline CI/CD funciona inmediatamente
    - No requiere reestructuraci√≥n de directorios ahora
    - Tests de backend siguen ejecut√°ndose en `make test` (contenedor backend)
  - ‚ö†Ô∏è **Perdemos:**
    - Deuda t√©cnica: estructura de tests mixta (no sigue Clean Architecture)
    - Fragilidad: cada nuevo test backend en `tests/unit/` requiere --ignore adicional
    - Confusi√≥n: no es obvio por nombre de archivo que pertenece a capa backend
  - üîß **Acci√≥n Futura (Post-MVP):**
    - Crear `tests/backend/unit/` y `tests/backend/integration/`
    - Crear `tests/agent/unit/` y `tests/agent/integration/`
    - Mover tests existentes a sus directorios correctos
    - Actualizar Makefile con `make test-backend` y `make test-agent` limpios
    - Referencia: T-028-BACK prompts.md #105

---

  - ‚úÖ **Ganamos:** [beneficios]
  - ‚ö†Ô∏è **Perdemos:** [trade-offs]
```
