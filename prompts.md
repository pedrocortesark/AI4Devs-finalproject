# REGISTRO DE PROMPTS UTILIZADOS
**Autor**: Pedro Cortes
**Proyecto**: ai4devs - TFM
**Descripción**: Bitácora de prompts para trazabilidad del proyecto.
---

## ESTRATEGIA DE GESTIÓN (ARCHIVADO)
Para mantener este registro manejable:
1. **Archivo Histórico:** Mueve prompts antiguos (ej. de fases exploratorias abandonadas) a `memory-bank/archive/`.
2. **Índice:** Añade una Tabla de Contenidos (TOC) para navegación rápida si el archivo supera las 1000 líneas.
3. **Rotación:** Considera dividir por años (`prompts-2026.md`) en proyectos de larga duración.

---
## 001 - Inicialización del Memory Bank
**Fecha:** 2025-12-19 07:43

**Prompt Original:**
> # Contexto / Rol
> Eres una instancia experta de **Gemini 3** operando como "Architect Agent" dentro de **Google Antigravity**.
> Debido a la naturaleza asíncrona y multi-agente de este IDE, tu responsabilidad es crear y mantener un **"Memory Bank" (Estado Compartido)**. Esto asegura que si un agente edita el frontend y otro los tests, ambos compartan el mismo contexto sin pisarse.
> 
> # Objetivo
> Generar la estructura de archivos de documentación y las **Reglas de Agente (.agent/rules)** para obligar a cualquier instancia de Gemini a leer el contexto antes de trabajar.
> 
> ## 1. Estructura de Archivos a Generar
> Analiza el repositorio (`@workspace`) y genera el contenido para estos archivos. Si no puedes crearlos directamente, dame el código Markdown de cada uno:
> 
> /memory-bank/
>  projectbrief.md      (Visión general del proyecto)
>  productContext.md    (Contexto de negocio y usuarios)
>  systemPatterns.md    (Arquitectura y diseño técnico)
>  techContext.md       (Stack, herramientas y comandos)
>  activeContext.md     (El estado actual "en vivo" del desarrollo)
>  progress.md          (Historial de cambios y deuda técnica)
> 
> /.agent/rules/
>  00-memory-bank.md    (Regla maestra de lectura obligatoria)
> 
> ## 2. Definición del Contenido (Archivos Core)
> 
> ### `memory-bank/projectbrief.md`
> - Resumen ejecutivo.
> - Objetivos clave.
> 
> ### `memory-bank/activeContext.md`
> - **Crítico:** Este archivo actúa como semáforo.
> - Debe contener: "¿En qué estamos trabajando AHORA MISMO?"
> - Lista de tareas activas.
> - Próximos pasos inmediatos.
> 
> ### `memory-bank/systemPatterns.md`
> - Arquitectura del sistema.
> - Mapa de carpetas clave.
> - Relaciones entre módulos (quién depende de quién).
> 
> ## 3. Configuración de la Regla (.agent/rules)
> 
> Genera el archivo **`.agent/rules/00-memory-bank.md`** con el siguiente contenido EXACTO. Esto es lo que forzará a los agentes a comportarse correctamente:
> 
> ```markdown
> ---
> description: "Mandatory Memory Bank Workflow"
> globs: ["**/*"]
> alwaysApply: true
> priority: critical
> ---
> 
> # AGENT MANDATE: Shared Memory Access
> 
> You are working in a multi-agent environment (Antigravity). You must rely on the Memory Bank for the single source of truth.
> 
> ## 1. Context Loading (READ FIRST)
> Before planning or executing ANY task, you MUST read:
> - `memory-bank/activeContext.md` -> To understand current focus.
> - `memory-bank/systemPatterns.md` -> To respect architecture.
> - `memory-bank/techContext.md` -> To use correct tools/commands.
> 
> ## 2. Atomic Updates (WRITE BACK)
> After completing a task:
> 1.  **Update** `memory-bank/activeContext.md`: Remove your finished task, add the result.
> 2.  **Update** `memory-bank/progress.md`: Mark features as completed.
> 3.  **Self-Correction**: If you find `projectbrief.md` or `systemPatterns.md` outdated, update them immediately.
> 
> ## 3. Forbidden Actions
> - Do not invent commands not listed in `techContext.md`.
> - Do not modify core architecture without updating `systemPatterns.md` first.
> ```
> 
> ## 4. Procedimiento de Inicialización
> 1.  Ejecuta un escaneo profundo del repositorio.
> 2.  Redacta el contenido de todos los archivos de `/memory-bank/` basándote en el código existente.
> 3.  Crea la carpeta `.agent/rules/` y el archivo de reglas.
> 4.  Confírmame cuando el "Cerebro del Proyecto" esté activo.

**Resumen de la Respuesta/Acción:**
Creé la estructura completa del Memory Bank con 6 archivos de documentación (`projectbrief.md`, `productContext.md`, `systemPatterns.md`, `techContext.md`, `activeContext.md`, `progress.md`) y las reglas obligatorias en `.agent/rules/00-memory-bank.md` que fuerzan a todos los agentes a leer el contexto antes de trabajar.

---

## 002 - Configuración de Logging de Decisiones
**Fecha:** 2025-12-19 08:18

**Prompt Original:**
> # Contexto
> Estamos iniciando un proyecto desde cero. Quiero asegurar que la documentación crezca orgánicamente junto con el código y no se convierta en una tarea aburrida para después.
> 
> # Objetivo
> Configurar el repositorio para que **cualquier cambio** en arquitectura, alcance o decisiones técnicas dispare obligatoriamente una actualización en el Memory Bank.
> 
> # Instrucciones de Ejecución
> 
> ## 1. Crear el Registro de Decisiones
> Genera un nuevo archivo `memory-bank/decisions.md`.
> Este archivo debe funcionar como un "Log de Decisiones" (ADR simplificado).
> Estructura inicial sugerida:
> ```markdown
> # Registro de Decisiones Arquitectónicas y de Producto
> 
> ## [FECHA] - [TÍTULO CORTO]
> - **Contexto:** Qué problema teníamos.
> - **Decisión:** Qué elegimos (ej. usar Tailwind en lugar de CSS puro).
> - **Consecuencias:** Qué ganamos y qué perdemos.

**Resumen de la Respuesta/Acción:**
Creé `memory-bank/decisions.md` con estructura ADR y actualicé `.agent/rules/00-memory-bank.md` añadiendo una sección obligatoria de "Decision Logging" que requiere documentar todas las decisiones arquitectónicas, de alcance o técnicas en tiempo real.

---

## 003 - Investigación de Mercado AI ConTech
**Fecha:** 2025-12-19 15:16

**Prompt Original:**
> # Contexto / Rol
> Actúa como **@Strategist** (definido en `AGENTS.md`). Eres un experto en Investigación de Mercado ConTech, Arquitectura Computacional y Desarrollo de Producto.
> Estamos en la fase de **Discovery**. Quiero encontrar un "Océano Azul" donde mi perfil híbrido (Arquitecto + Developer Rhino/Grasshopper) tenga una ventaja injusta.
> 
> # Objetivo
> Realizar un análisis de mercado buscando problemas crónicos ("User Pains") no resueltos y documentar los hallazgos en un nuevo archivo del Memory Bank para referencia futura.
> 
> # Fuentes de Investigación (Browsing)
> Navega y analiza patrones en estas fuentes. Busca la frustración del usuario:
> 
> 1.  **McNeel Discourse (The Pain):**
>    * [Serengeti Wishes](https://discourse.mcneel.com/tags/c/serengeti/25/wish)
>    * [Wishlist Tag](https://discourse.mcneel.com/tag/wishlist)
>    * *Instrucción:* Busca hilos con muchas respuestas, quejas recurrentes sobre flujos de trabajo rotos, o peticiones de automatización ignoradas.
> 
> 2.  **Contech Database & Ecosystem (The Gap):**
>    * [Contech Database](https://contechdatabase.softr.app/)
>    * *Instrucción:* Identifica qué está saturado (ej. generación de plantas 2D) y qué está vacío.
> 
> # Output Esperado: Archivos del Memory Bank
> 
> No respondas solo con texto. Genera el código Markdown para crear y actualizar los siguientes archivos:
> 
> ## 1. CREAR: `memory-bank/market-analysis.md`
> Este será el repositorio de tu investigación. Usa esta estructura exacta:
> 
> ```markdown
> # Market Analysis: AI opportunities in Rhino/AEC
> 
> ## 1. Pain Points & User Wishes (Evidencia)
> * **[Nombre del Dolor]**: Descripción del problema.
>  * *Fuente:* [Link al hilo del foro]
>  * *Insight:* ¿Por qué es difícil de resolver sin AI?
> 
> ## 2. Competitor Landscape
> * **Océanos Rojos (Saturado):** ...
> * **Océanos Azules (Oportunidad):** ...
> 
> ## 3. Strategic Proposals (3 Blue Oceans)
> Propón 3 ideas concretas que aprovechen mi expertise (Rhino+Dev+AI):
> 1.  **[Idea A]**: Concepto + Por qué es viable.
> 2.  **[Idea B]**: Concepto + Por qué es viable.
> 3.  **[Idea C]**: Concepto + Por qué es viable.
> ```
> 
> ## 2. ACTUALIZAR: `memory-bank/activeContext.md`
> Actualiza la sección de estado:
> * **Current Focus:** Investigación de mercado finalizada. Revisando propuestas en `market-analysis.md`.
> * **Next Step:** Seleccionar una propuesta ganadora.
> 
> ## 3. ACTUALIZAR: `memory-bank/decisions.md`
> Añade la entrada:
> * **Fecha:** [Hoy]
> * **Decisión:** Investigación de mercado consolidada.
> * **Contexto:** Se ha creado `market-analysis.md` para evitar "ruido" en el product context principal.
> 
> # Ejecución
> Procede con la navegación y la generación de archivos.

**Resumen de la Respuesta/Acción:**
Navegué McNeel Discourse y Contech Database identificando 3 pain points principales (optimización geométrica para manufactura, gestión de archivos externos/XREF, automatización de organización de objetos) y propuse 3 océanos azules: Semantic Rhino (AI Layering), SmartFabricator (Manufacturing Prep), y AEC Interaction Copilot (NL Interface). Recomendación: Semantic Rhino como TOP PICK por ser el camino más rápido al mercado.

---

## 004 - Análisis de Viabilidad Smart XREF
**Fecha:** 2025-12-23 13:41

**Prompt Original:**
> # Prompt: Análisis de Viabilidad y Estrategia - Smart Large Model Management
> 
> **Role:** Actúa como un **Lead Technical Product Manager** y **Solutions Architect** con experiencia en CAD y sistemas distribuidos. Tu mentalidad debe ser crítica, analítica y orientada a riesgos.
> 
> **Contexto:**
> Estoy evaluando pivotar mi Proyecto Final de Máster (TFM) hacia una solución de "Gestión Inteligente de Grandes Modelos" (Smart XREF) para Rhino.
> La idea base es sustituir el sistema actual de "Worksessions" (que es rígido y carga todo el archivo) por un sistema de **Indexado y Carga Granular**.
> *Hipótesis:* El usuario debería poder decir "Carga solo la estructura de la Planta 2" sin abrir el archivo original, gracias a un pre-procesado de datos.
> 
> **Objetivo:**
> NO quiero código ni implementación todavía. Quiero un **Análisis de Viabilidad y Estrategia Profunda**. Necesito que valides si la idea tiene sentido técnico y comercial, o si hay barreras insalvables.
> 
> **Tareas de Análisis:**
> 
> 1.  **El "Stress Test" Técnico (Cuellos de Botella):**
>    * Analiza el problema de la **Latencia y "Data Gravity"**: Si un archivo pesa 2GB, ¿es realista subirlo a la nube para indexarlo? ¿Cuánto tardaría? ¿Sería mejor una indexación local?
>    * Analiza la limitación de `Rhino.Compute` o `rhino3dm`: ¿Son capaces de leer un archivo masivo sin "explotar" la memoria RAM?
> 
> 2.  **Análisis del "Por qué no existe":**
>    * Actúa como abogado del diablo. ¿Por qué McNeel (creadores de Rhino) o Speckle no han resuelto esto aún?
>    * ¿Es un problema de tecnología (no se podía hacer antes) o de flujo de trabajo (los arquitectos no trabajan así)?
> 
> 3.  **Evaluación de Estrategias de Indexado (Comparativa):**
>    * Compara tres enfoques posibles y dime cuál es el más viable para un TFM (un solo desarrollador, 3 meses):
>        * *Opción A:* Base de datos SQL clásica (indexar solo metadatos: capas, nombres).
>        * *Opción B:* Base de datos Vectorial (indexar "forma" y geometría para búsqueda visual).
>        * *Opción C:* Indexado ligero local (generar archivos proxy/baja resolución).
> 
> 4.  **Definición de Escenarios de Uso (User Stories):**
>    * Describe un caso de uso donde esta herramienta ahorre horas de trabajo reales.
>    * Describe un caso donde la herramienta podría fallar estrepitosamente (ej: archivos mal modelados).
> 
> **Output esperado:** Un informe crítico estructurado. Sé brutalmente honesto sobre la complejidad. Si crees que es demasiado para un TFM, sugiérelo.

**Resumen de la Respuesta/Acción:**
Realizaré un análisis crítico de viabilidad técnica y comercial para el sistema Smart XREF, evaluando cuellos de botella (latencia, memoria), razones por las que no existe (abogado del diablo), comparativa de estrategias de indexado, y escenarios de uso reales. El output será un informe estructurado en `feasibility-smart-xref.md`.

---

## 005 - Análisis de Viabilidad Semantic Rhino
**Fecha:** 2025-12-23 14:09

**Prompt Original:**
> # Prompt: Análisis de Viabilidad Técnica y Estratégica - Semantic Rhino (Auto-Classifier)
> 
> **Role:** Actúa como un **Lead AI Engineer** y **Product Manager** especializado en el sector AEC (Architecture, Engineering, Construction). Tu enfoque debe ser pragmático: prioriza soluciones que funcionen en producción sobre las académicamente complejas.
> 
> **Contexto:**
> Estoy evaluando una de las ideas finalistas para mi TFM. El concepto es **"Semantic Rhino"**: Un plugin que clasifica automáticamente geometría desorganizada en capas estandarizadas (ej: de "Layer 01" a "Muro-Exterior").
> El análisis de mercado indica que es un dolor crónico debido a la falta de estandarización en los modelos importados.
> 
> **Objetivo:**
> Realizar un análisis crítico de viabilidad técnica y definición de MVP. Quiero saber si es realista construir esto en 3 meses y cuál es la arquitectura más inteligente.
> 
> **Tareas de Análisis:**
> 
> 1.  **El Dilema del "Core" de IA (Deep Learning vs. Heurística + LLM):**
>    * El concepto original sugiere usar "Redes Neuronales Geométricas" (PointNet, Graph CNNs). Critica esta aproximación para un TFM. ¿Es "matar moscas a cañonazos"?
>    * Analiza la viabilidad de una aproximación **Híbrida**: Usar LLMs para analizar nombres de capas/bloques (texto) + Algoritmos geométricos clásicos (Bounding Box, Normales, Volumen) para desambiguar.
>    * ¿Qué approach tiene mejor retorno de inversión (ROI) de desarrollo?
> 
> 2.  **El Problema de los Datos (Data Scarcity):**
>    * Para entrenar una IA que reconozca un "Muro" solo por su forma, necesito miles de muros etiquetados. No tengo ese dataset.
>    * Propón una estrategia "Zero-Shot" o "Few-Shot". ¿Podemos clasificar sin entrenar un modelo desde cero? (Ej: Usar embeddings de CLIP 3D o descriptores matemáticos).
> 
> 3.  **UX y Confianza (Trust):**
>    * Si la IA mueve 5.000 objetos de capa y se equivoca en el 5%, el usuario pierde confianza.
>    * Diseña (conceptualmente) el flujo de "Human-in-the-loop". ¿Cómo puede el usuario validar la clasificación rápidamente antes de confirmar?
> 
> 4.  **Definición del MVP (Alcance TFM):**
>    * Define un alcance acotado. En lugar de clasificar *todo* el edificio, ¿deberíamos centrarnos solo en "Elementos Estructurales" (Pilares, Vigas, Losas)?
>    * Propón el stack tecnológico: ¿Rhino.Compute local? ¿API de OpenAI? ¿Librerías de Python como `trimesh` o `scikit-learn`?
> 
> **Output esperado:**
> Un informe que compare la vía "Académica" (3D Deep Learning) vs. la vía "Pragmática" (Feature Engineering + LLM), recomendando la mejor ruta para un proyecto individual de máster.

**Resumen de la Respuesta/Acción:**
Realizaré análisis comparativo Deep Learning (PointNet) vs. Hybrid (LLM + geometric features). Evaluaré estrategias zero-shot/few-shot para evitar necesidad de dataset etiquetado. Diseñaré flujo human-in-the-loop para validación. Definiré MVP enfocado en elementos estructurales con stack tecnológico pragmático para 3 meses.

---

## 006 - Análisis de Viabilidad SmartFabricator
**Fecha:** 2025-12-24 08:10

**Prompt Original:**
> # Prompt: Análisis de Viabilidad Técnica - SmartFabricator (AI for CNC/Laser)
> 
> **Role:** Actúa como un **Lead R&D Engineer** en Digital Fabrication y Experto en Geometría Computacional. Tu perfil combina conocimientos de IA (Reinforcement Learning) con la realidad dura del taller (CNC, Tolerancias, G-Code).
> 
> **Contexto:**
> Estoy evaluando la tercera opción para mi TFM: **"SmartFabricator"**.
> La promesa es usar IA para convertir geometría NURBS compleja de Rhino en instrucciones listas para fabricación (G-code o DXF optimizado), minimizando desperdicio y respetando limitaciones de material.
> El análisis de mercado valida el problema: la conversión de curvas a arcos y el nesting manual son dolores diarios.
> 
> **Hipótesis Técnica:**
> La propuesta sugiere usar **Reinforcement Learning (RL)** para una optimización multi-objetivo (precisión vs. coste vs. velocidad).
> 
> **Objetivo:**
> Realizar un "Reality Check" técnico. El papel lo aguanta todo, pero el hardware no. Necesito saber si es viable prototipar esto sin acceso a un laboratorio industrial 24/7.
> 
> **Tareas de Análisis:**
> 
> 1.  **Crítica al Enfoque de Reinforcement Learning (RL):**
>    * El RL requiere un "entorno" de simulación para entrenarse (millones de iteraciones). ¿Es viable crear un simulador de corte láser/CNC realista en Python como parte de un TFM?
>    * ¿Sería más inteligente usar **Algoritmos Genéticos** o **Optimización Convexa** clásica en lugar de Deep RL? Compara la complejidad de implementación vs. beneficio.
> 
> 2.  **El Problema de la "Alucinación" en G-Code:**
>    * Si un LLM o una red neuronal genera texto (G-code) y se equivoca en una coordenada, la máquina puede chocar físicamente.
>    * Analiza el riesgo de generar G-code directamente. ¿Deberíamos limitar el alcance a generar solo **Geometría Optimizada** (DXF limpio, Arcos perfectos) y dejar que el software CAM tradicional haga el G-code?
> 
> 3.  **Definición del MVP (El problema "Curve to Arc"):**
>    * El análisis menciona el deseo de "convertir curvas a arcos/polilíneas".
>    * ¿Podría ser este el MVP perfecto? Una herramienta pequeña que tome una Spline compleja y use IA para encontrar la mejor aproximación con arcos tangentes (ideal para máquinas CNC antiguas).
>    * Evalúa si esto es suficiente para un TFM de "AI Engineer" o si se queda corto.
> 
> 4.  **Comparativa de Mercado (Nesting):**
>    * Ya existen herramientas como DeepNest (Open Source). ¿Qué valor añadiría una IA aquí? ¿Velocidad? ¿Mejor uso de retales?
> 
> **Output esperado:**
> Una recomendación honesta sobre si perseguir esta idea (High Risk / High Reward) o si la barrera de entrada técnica (simulación física) es demasiado alta para 3 meses.

**Resumen de la Respuesta/Acción:**
Realizaré reality check técnico para SmartFabricator. Evaluaré viabilidad de RL (requiere simulador), compararé con algoritmos clásicos (Genéticos, Convexa), analizaré riesgo de generación directa de G-code, evaluaré MVP curve-to-arc,  y compararé con DeepNest. Recomendación honesta sobre high-risk vs. barrera técnica.

---

## 007 - Análisis de Viabilidad AEC Interaction Copilot
**Fecha:** 2025-12-26 08:03

**Prompt Original:**
> # Prompt: Análisis de Viabilidad y Riesgos - AEC Interaction Copilot (NL to Script)
> 
> **Role:** Actúa como un **Lead Software Architect** especializado en Integraciones LLM y Seguridad en Entornos de Escritorio. Tienes experiencia profunda en la API de Rhino (RhinoCommon) y en los riesgos de la ejecución de código arbitrario.
> 
> **Contexto:**
> Estoy evaluando la opción final para mi TFM: **"AEC Interaction Copilot"**.
> El concepto es una interfaz tipo chat dentro de Rhino que permite ejecutar operaciones complejas mediante lenguaje natural ("Selecciona todos los objetos con volumen > 10m³ y ponlos en la capa Estructura").
> El análisis de mercado sugiere que esto es viable porque los LLMs actuales (GPT-4) ya generan Python competente y mi experiencia en Grasshopper permite crear "guardrails" (mecanismos de seguridad).
> 
> **Hipótesis Técnica:**
> En lugar de crear botones, usamos un LLM para traducir Intención del Usuario -> Script de Python/RhinoCommon -> Ejecución en Rhino.
> 
> **Objetivo:**
> Realizar un análisis forense de la idea. Quiero saber si esto es un producto real o solo una demo divertida que nadie usará profesionalmente.
> 
> **Tareas de Análisis:**
> 
> 1.  **El Problema de la "Alucinación Destructiva" (Safety):**
>    * Si la IA genera un script que dice `rs.DeleteObjects(rs.AllObjects())` por error, el usuario pierde el trabajo.
>    * Analiza críticamente el riesgo de ejecutar código generado por LLM en un entorno de producción local. ¿Qué "guardrails" reales son técnicamente posibles? (¿Sandboxing? ¿Dry-run/Preview?).
> 
> 2.  **El Reto del Contexto (Context Awareness):**
>    * Para que la IA diga "Mueve *esa* columna", la IA necesita saber qué es "*esa* columna". Los LLMs son ciegos al Viewport de Rhino.
>    * ¿Cómo inyectamos el estado del modelo (GUIDs, capas, selección actual) en el prompt sin exceder la ventana de contexto o gastar una fortuna en tokens?
> 
> 3.  **Code Gen vs. Graph Gen:**
>    * La propuesta menciona "Generate Grasshopper definitions".
>    * Critica esto: ¿Es realista generar archivos XML/binarios de Grasshopper (.gh) funcionales mediante texto? ¿O es mucho más sensato generar scripts de Python (`rhinoscriptsyntax`) que hagan lo mismo? Compara la viabilidad de ambos para un TFM.
> 
> 4.  **Análisis de Valor (Speed vs. Typing):**
>    * Escribir "Haz una caja de 10x10x10" tarda 5 segundos. Hacer clic en el icono de caja tarda 1 segundo.
>    * Identifica los casos de uso donde el Chat es *realmente* más rápido (ej: selecciones complejas, batch processing) y descarta los que son peores que la interfaz gráfica.
> 
> **Output esperado:**
> Una hoja de ruta crítica. Si recomiendas seguir adelante, define la arquitectura de seguridad imprescindible para no romper los archivos de los usuarios.

**Resumen de la Respuesta/Acción:**
Realizaré análisis forense de AEC Copilot evaluando riesgos de ejecución de código (alucinación destructiva), estrategias de guardrails (sandboxing, dry-run), inyección de contexto Rhino (GUIDs, capas), viabilidad Python vs. Grasshopper XML, y análisis crítico de casos de uso donde NL supera GUI vs. donde falla. Arquitectura de seguridad si procede.

---

## 008 - Análisis de Viabilidad AEC-NeuralSync (Federated Learning + Private Weights)
**Fecha:** 2025-12-26 10:03

**Prompt Original:**
> # Prompt: Análisis de Viabilidad y Seguridad - AEC-NeuralSync (Private Knowledge & Weights Exchange)
> 
> **Role:** Actúa como un **CTO & Chief AI Architect** con especialización en **Privacidad de Datos (Federated Learning/LoRA)** y **Diseño Computacional (AEC)**. Tienes experiencia implementando soluciones de IA en entornos corporativos donde la Propiedad Intelectual (IP) y los activos algorítmicos son críticos.
> 
> **Contexto:**
> Estoy desarrollando mi Trabajo de Fin de Máster (TFM) para el programa **ai4devs** titulado: **"AEC-NeuralSync"**. 
> El objetivo es crear un sistema que permita a estudios de arquitectura e ingenierías (usuarios de Rhino/Grasshopper) entrenar y consultar su propia "Lógica de Diseño" de forma privada y soberana. 
> 
> La innovación reside en un modelo híbrido: 
> 1. **RAG local** para búsqueda semántica de archivos `.gh` y scripts.
> 2. **Fine-tuning (LoRA) local** para capturar patrones de diseño y flujos de trabajo específicos.
> 3. **Weights Exchange:** Mi tesis es que puedo recopilar únicamente los adaptadores (pesos LoRA) de los clientes para mejorar un "Modelo Maestro" sin que los datos sensibles (geometría, planos, modelos 3D) abandonen jamás la infraestructura del cliente.
> 
> **Hipótesis Técnica:**
> * Los archivos binarios de Grasshopper (.gh) se convierten en texto estructurado (JSON/XML/GHX) localmente.
> * Un LLM local (ej. Llama 3.1/3.2 u Ollama) procesa estos datos para el RAG y el entrenamiento.
> * El único output que viaja a mis servidores es el archivo del adaptador LoRA (~50MB - 200MB), garantizando el anonimato de la geometría original.
> 
> **Tareas de Análisis Crítico Requeridas:**
> 
> ### 1. Desmitificación de la "Soberanía del Dato" (Security Audit)
> * Analiza críticamente la afirmación: *"Los pesos (LoRA) no permiten reverse-engineering de los datos originales"*. 
> * Evalúa riesgos reales de **Training Data Extraction Attacks** en modelos de lenguaje pequeños aplicados a código/lógica. ¿Qué medidas de seguridad adicionales (ej. Differential Privacy o Gradient Clipping) debería proponer para que el departamento legal de una gran ingeniería valide el sistema?
> 
> ### 2. El Desafío de la Serialización de Grafos (The GH-to-LLM Bridge)
> * Grasshopper es un Grafo Acíclico Dirigido (DAG). Los LLMs son procesadores de secuencias (texto).
> * Evalúa la viabilidad de traducir una definición compleja de GH a un formato que mantenga la jerarquía lógica. ¿Es mejor un enfoque de **Grafo-a-Texto (Graph-to-Text)**, un aplanamiento a **JSON estructurado**, o entrenar al modelo directamente en el XML de `.ghx`? ¿Cómo manejamos la pérdida de contexto en definiciones con cientos de nodos?
> 
> ### 3. Escalabilidad del "Model Merging" (The Business Core)
> * Mi escalabilidad depende de fusionar pesos de diferentes clientes.
> * Analiza la viabilidad técnica de **LoRA Merging / Model Soups**. Si fusiono pesos de un estudio experto en fachadas con uno experto en estructuras: ¿El modelo resultante hereda ambas capacidades o se produce una degradación por interferencia de pesos ("catastrophic forgetting")?
> 
> ### 4. UX/DX: Integración en el Workflow del Arquitecto
> * Compara dos interfaces de implementación en Rhino/Grasshopper: 
>    * **A) Agente de Chat (Side-panel):** Recupera y sugiere definiciones o fragmentos de código.
>    * **B) Autocompletado Proactivo (Ghost-nodes):** Predice el siguiente nodo o conexión en el lienzo basándose en el fine-tuning.
> * ¿Cuál aporta un ROI más claro para una empresa y cuál es más factible de prototipar como MVP para un máster de desarrollo?
> 
> **Output esperado:**
> Un informe técnico de "Riesgos y Oportunidades". Sé despiadado con las debilidades de la arquitectura y define el **Stack Tecnológico mínimo viable** (Lenguajes, librerías de IA y APIs de Rhino) para demostrar la transferencia de pesos segura.
> 
> **Protocolo**
> Lee los archivos relativos al memory bank y el específico de reglas `AGENTS.md` para seguir lo indicado en generacion de documentos y modificacion del archivo de prompts

**Resumen de la Respuesta/Acción:**
Siguiendo protocolo AGENTS.md: Loggear prompt completo primero. Luego analizaré críticamente AEC-NeuralSync evaluando claims de privacidad LoRA (riesgo extracción datos), serialización GH-to-LLM (DAG a secuencia), viabilidad LoRA merging (catastrophic forgetting), y UX chat vs. autocomplete. Definiré stack tecnológico mínimo viable y compararé complejidad con 4 opciones previas para TFM.

---

## 009 - Análisis de Viabilidad GH-Copilot (Predictive Node Engine)
**Fecha:** 2025-12-30 21:51

**Prompt Original:**
> # Prompt: Análisis de Arquitectura y Viabilidad - GH-Copilot (Predictive Node Engine)
> 
> **Role:** Actúa como un **Lead AI Engineer** y **Experto en Geometría Computacional**. Tienes experiencia profunda en el SDK de Grasshopper (GH_IO.dll) y en el entrenamiento de modelos de lenguaje para la generación de código y estructuras de grafos.
> 
> **Contexto:**
> Estoy diseñando mi TFM para **ai4devs**: un **Copilot para Grasshopper**. 
> La idea es procesar una biblioteca privada de archivos `.gh`, extraer su lógica algorítmica y entrenar un modelo (Fine-tuning con LoRA) para que un plugin de Grasshopper pueda sugerir "bloques de componentes" o "nodos siguientes" en tiempo real, basándose en el estilo y conocimiento técnico previo del estudio.
> 
> **Hipótesis Técnica:**
> 1. **Extracción:** Convertimos archivos `.gh` o `.ghx` en una representación de texto que preserve la topología del grafo (conexiones, tipos de nodos y parámetros).
> 2. **Entrenamiento:** Realizamos un fine-tuning local de un modelo (ej: Llama 3.2 o Phi-3.5) para que aprenda a completar secuencias de nodos.
> 3. **Inferencia:** El plugin de GH envía el estado actual del lienzo (nodos presentes) y la IA devuelve una predicción de los siguientes componentes lógicos.
> 
> **Tareas de Análisis Crítico:**
> 
> ### 1. El Reto de la Serialización de Grafos (DAG to Sequence)
> * Grasshopper es un Grafo Acíclico Dirigido (DAG). Para entrenar un LLM, necesito "aplanar" ese grafo a texto.
> * Analiza: ¿Cuál es el formato más eficiente para que el modelo aprenda? 
>    * ¿JSON estructurado? 
>    * ¿Una pseudo-sintaxis tipo "NodeA[Out] -> NodeB[In]"? 
>    * ¿O entrenar directamente sobre el XML de `.ghx` ignorando los metadatos de posición visual (X, Y)?
> * Evalúa cómo manejar los **GUIDs**: Los componentes tienen IDs únicos que cambian en cada archivo. ¿Cómo hacemos que el modelo aprenda "conceptos" de nodos y no IDs aleatorios?
> 
> ### 2. Fine-Tuning vs. RAG para Predicción de Nodos
> * Compara dos estrategias para el MVP del máster:
>    * **A) Fine-tuning (LoRA):** El modelo "sabe" qué nodo sigue porque ha internalizado los patrones.
>    * **B) RAG de Grafos:** El sistema busca en una base de datos vectorial sub-grafos similares al que el usuario está dibujando y los "pega" como sugerencia.
> * ¿Cuál es más viable para un desarrollo de 3 meses y cuál ofrece una respuesta más rápida (latencia) dentro de Rhino?
> 
> ### 3. UX: La Interfaz de "Sugerencia Proactiva"
> * Proponer un solo nodo es poco útil. Proponer un "bloque" (ej: todo el setup de un análisis de radiación) es muy valioso.
> * Analiza la dificultad técnica de implementar **"Ghost Nodes"** (nodos semi-transparentes que el usuario puede aceptar con 'Tab') frente a un **panel lateral de sugerencias**. 
> * ¿Cómo podemos inyectar los componentes predichos directamente en el lienzo de Grasshopper usando C#?
> 
> ### 4. Privacidad y Modelo de Negocio "Weights-Only"
> * El usuario quiere que sus definiciones no salgan de su servidor. 
> * Evalúa la seguridad de entrenar localmente y solo subir los adaptadores LoRA. 
> * ¿Es posible que el modelo "olvide" la lógica general al ser sobre-entrenado con datos muy específicos de un solo estudio (Overfitting)?
> 
> **Output esperado:**
> Una hoja de ruta técnica que defina el **Pipeline de Datos** (de `.gh` a Dataset de entrenamiento) y el **Stack Tecnológico** recomendado (librerías de Python para el modelo y APIs de Rhino para el plugin). Identifica el "cuello de botella" más probable del proyecto.

**Resumen de la Respuesta/Acción:**
Analizaré GH-Copilot (6ª opción): Evaluaré serialización DAG-to-sequence para GH (JSON vs. pseudo-sintaxis vs. XML directo, manejo GUIDs), compararé fine-tuning LoRA vs. RAG (viabilidad 3 meses, latencia), analizaré UX Ghost Nodes vs. panel lateral (implementación C# GH SDK), y evaluaré privacidad local-only LoRA (riesgo overfitting). Definiré pipeline datos y stack tecnológico, identificando cuellos de botella. Compararé con 5 opciones previas.

---

## 010 - Análisis de Viabilidad Sistema Gestión Piezas Sagrada Familia
**Fecha:** 2026-01-13 10:09

**Prompt Original:**
> # Prompt: Análisis de Arquitectura y Viabilidad – Sistema de Gestión de Piezas para Sagrada Familia
> 
> **Role:** Actúa como un **Lead Software Architect** y **Experto en Integración CAD/BIM**. Tienes experiencia en proyectos de gran escala en AEC, gestión de ciclo de vida de piezas, y desarrollo de agentes inteligentes para automatización y control de calidad de datos.
> 
> **Contexto:**  
> Estoy diseñando mi TFM para **ai4devs**: un **sistema de gestión integral de piezas para la Sagrada Familia**.  
> El objetivo es procesar archivos `.3dm` de Rhino generados por nuestro propio equipo, extraer y clasificar automáticamente cada pieza, y registrar su ciclo de vida completo en una base de datos. El sistema debe soportar miles de piezas, múltiples roles de usuario (arquitectos, industriales, etc.), control de acceso granular y visualización 3D interactiva (Three.js).
> Que no se te olvide registrar este prompt siguiendo el protocolo AGENTS.md y modificar los archivos correspondientes del memory bank.
> 
> **Hipótesis Técnica:**
> 1. **Extracción:** El backend procesa archivos Rhino (.3dm) usando rhino3dm, identifica y extrae cada pieza y sus metadatos.
> 2. **Clasificación:** Un agente inteligente (tipo LangChain y LangGraph) clasifica y enriquece los datos de cada pieza (tipo, estado, responsable, etc.).
> 3. **Gestión:** Cada pieza se almacena como entrada en una base de datos, con historial de eventos y cambios de estado.
> 4. **Acceso:** El sistema implementa control de acceso por roles, permitiendo a cada usuario ver y editar solo la información relevante.
> 5. **Visualización:** El frontend permite explorar y filtrar piezas, y visualizarlas en 3D mediante Three.js.
> 
> **Tareas de Análisis Crítico:**
> 
> ### 1. Escalabilidad y Procesamiento Masivo de Archivos Rhino
> * Analiza la viabilidad de procesar y extraer datos de miles de piezas desde archivos `.3dm` de gran tamaño.
> * ¿Qué limitaciones tiene rhino3dm para extracción masiva? ¿Es mejor procesar por lotes o pieza a pieza?
> * ¿Cómo asegurar la integridad y unicidad de cada pieza en la base de datos?
> 
> ### 2. Diseño del Agente Inteligente
> * ¿Qué tareas puede automatizar el agente (clasificación, enriquecimiento, validación, notificaciones)?
> * ¿Qué arquitectura de memoria/contexto es más adecuada para mantener trazabilidad y eficiencia?
> * ¿Cómo se puede integrar el agente con el flujo de eventos y cambios de estado de cada pieza?
> 
> ### 3. Modelo de Datos y Control de Acceso
> * Propón un modelo de datos que permita registrar el ciclo de vida completo de cada pieza, con historial y metadatos extensibles.
> * ¿Cómo diseñar un sistema de roles y permisos flexible para arquitectos, industriales y otros perfiles?
> * ¿Qué riesgos existen en la gestión concurrente de miles de piezas y cómo mitigarlos?
> 
> ### 4. Visualización 3D y Experiencia de Usuario
> * Evalúa la mejor estrategia para convertir geometría Rhino a formatos compatibles con Three.js (glTF, OBJ, JSON).
> * ¿Cómo optimizar la visualización interactiva de miles de piezas en canvas 3D?
> * ¿Cómo almacenamos la información geométrica en una base de datos para que pueda ser consultada y visualizada en un canvas 3D?
> * ¿Qué patrones de UI/UX facilitan la navegación, filtrado y edición masiva de piezas?
> 
> ### 5. Automatización, Notificaciones y Trazabilidad
> * ¿Cómo puede el agente detectar estados críticos, retrasos o inconsistencias y notificar automáticamente a los usuarios?
> * ¿Qué mecanismos asegurarían la trazabilidad total de cada cambio y evento en el ciclo de vida de una pieza?
> 
> **Output esperado:**  
> Un documento de viabilidad técnica que defina el **pipeline de datos** (de `.3dm` a base de datos y visualización), el **stack tecnológico recomendado** (librerías, frameworks, arquitectura de agente), y los principales cuellos de botella o riesgos del proyecto. Incluye recomendaciones para el MVP y para la escalabilidad futura.

**Resumen de la Respuesta/Acción:**
Analizaré viabilidad de "Sistema Gestión Piezas Sagrada Familia". Evaluación técnica: extracción masiva con rhino3dm vs Compute, arquitectura agente LangGraph para clasificación, modelo de datos relacional con control de acceso RBAC, pipeline visualización 3dm->glTF->Three.js, y trazabilidad eventos. Definiré stack tecnológico y roadmap MVP TFM. Compararé con opciones previas (aunque este caso parece un pivot hacia un caso real/industrial).

---

## 011 - Oficialización de Proyecto Sagrada Familia (Systems Architect Path)
**Fecha:** 2026-01-20 06:12

**Prompt Original:**
> # Prompt: Oficialización de Proyecto y Actualización de Contexto
> 
> **Role:** Actúa como el **Project Manager** y **Keeper del Memory Bank** del proyecto AI4Devs TFM.
> 
> **Instrucción:**
> Procedemos a oficializar la elección del proyecto para el Trabajo de Fin de Máster.
> Por favor, actualiza los archivos de memoria (`productContext.md`, `Project_Log.md` y `decisions.md`) con la siguiente información definitiva:
> 
> 1.  **Proyecto Seleccionado:** "Sagrada Familia Parts Manager" (Enterprise Digital Twin System).
> 2.  **Identidad del Producto:**
>    * **Tipo:** Sistema de Gestión de Inventario Digital 3D & Trazabilidad Logística.
>    * **Enfoque:** Systems Architecture, BIM Integration, Hybrid AI Agents (LangGraph).
>    * **Diferenciación:** Solución "Enterprise/Industrial" frente a herramientas "SaaS generalistas". Simulamos una entrega para un cliente de alto perfil (Patrimonio/Construcción Compleja).
> 3.  **Objetivos de Alto Nivel:**
>    * Demostrar capacidad de arquitectura de sistemas complejos (Front 3D + Back Data + AI).
>    * Resolver el problema de "Data Gravity" en modelos masivos mediante extracción híbrida (Metadata vs. Geometry).
>    * Implementar un "Agente Bibliotecario" (The Librarian) para normalización de datos.
> 
> **Acciones Requeridas en Archivos:**
> * **`productContext.md`:** Reemplaza el contexto de exploración por la descripción de este sistema específico. Define al "Usuario Principal" como el Gestor de BIM/Logística de la obra.
> * **`decisions.md`:** Registra la decisión de elegir este proyecto sobre "Semantic Rhino" y "SmartFabricator", citando el valor de portfolio "Senior Architect" y la viabilidad técnica controlada.
> * **`Project_Log.md`:** Cierra la fase de "Análisis de Viabilidad" e inicia la fase de "Definición de Producto (PRD)".
> * **`prompts.md`:** Actualizar con este prompt siguiendo con el protocolo agents.MD.

**Resumen de la Respuesta/Acción:**
Oficializaré "Sagrada Familia Parts Manager" como proyecto TFM. Actualizaré productContext.md con la nueva identidad (Systems Arch/Digital Twin). Registraré la decisión final en decisions.md (Selection vs Alternatives). Cerraré fase exploration en progress.md (Project_Log) e iniciaré fase PRD.

---

## 012 - Kickoff Oficial: README Maestro y Especificación Técnica Completa
**Fecha:** 2026-01-26 14:30

**Prompt Original:**
> # Plan: Kickoff "Sagrada Familia Parts Manager" & README Maestro (Technical Specification)
>
> Creación del README.md como **Single Source of Truth técnico** del proyecto SF-PM, documentando arquitectura completa, stack, modelo de datos, y roadmap de features por valor de negocio para presentación a inversores. Incluye actualización de memoria del proyecto y registro del prompt #012.
>
> ## Steps
>
> 1. **Registrar Prompt #012 en prompts.md**: Añadir entrada secuencial después del #011, con fecha 2026-01-26 14:30, prompt literal completo del kickoff oficial, y resumen de creación del README maestro con especificación técnica.
>
> 2. **Actualizar memory-bank/productContext.md**: Redefinir como "Sistema Enterprise de Trazabilidad para Patrimonio Arquitectónico Complejo", enfocando en Oficina Técnica como usuario principal, y destacando el Digital Twin Activo con validación ISO-19650 mediante The Librarian Agent.
>
> 3. **Actualizar memory-bank/decisions.md**: Registrar decisión #013 del kickoff oficial (2026-01-26) justificando enfoque en Architecture & Systems, estrategia de MVP para inversores, y elección de README como documentación técnica centralizada.
>
> 4. **Crear README.md** estructurado en 8 secciones: 
>   - **Encabezado** (nombre, tagline, estado en desarrollo, badges)
>   - **Fase 1: Contexto y Estrategia** (problema Data Gravity en SF, propuesta Digital Twin Activo)
>   - **Fase 2: Definición del Producto** con subsecciones:
>     - User Personas detalladas (Arquitecto/BIM Manager/Gestor de Piedra)
>     - Arquitectura del Sistema (diagrama textual del flujo de validación The Librarian con ISO-19650)
>     - Stack Tecnológico completo (Frontend: React+Three.js+React-Three-Fiber. Analizar ThatOpenCompany; Backend: FastAPI+rhino3dm+Celery; Data: PostgreSQL/Supabase+S3; AI: LangGraph)
>     - Modelo de Datos (esquema PostgreSQL con tablas `parts`, `geometry`, `metadata`, `events`)
>     - Roadmap de Features por valor de negocio (P0-MVP: Carga+Validación+Visor3D; P1-Scale: Búsqueda+RBAC+Audit; P2-Enterprise: API+Integraciones)
>   - **Fases 3-4 Placeholder** (Casos de Uso, Deployment)
>
> 5. **Formular 3-5 preguntas técnicas bloqueantes** como Tech Lead:
>   - Estructura monorepo (apps/frontend, apps/backend, packages/shared vs alternativas)
>   - Almacenamiento de archivos pesados (.3dm, .glb) con estrategia Git LFS vs Supabase Storage vs AWS S3
>   - Arquitectura de procesamiento asíncrono (Celery+Redis vs BullMQ vs Temporal)
>   - Configuración inicial de autenticación (Supabase Auth built-in vs JWT custom)
>   - Estrategia de testing (Jest+Pytest vs Vitest+Pytest vs alternativas)
>
> ## Further Considerations
>
> 1. **Nivel de profundidad en diagramas de arquitectura**: ¿Incluir diagramas ASCII/Mermaid en el README para flujos de datos (Upload Pipeline, Validation Workflow, 3D Rendering) o dejarlo como descripción textual detallada para mantener el documento limpio?
>
> 2. **Sección de métricas de éxito para inversores**: ¿Agregar apartado "Business Metrics" con KPIs técnicos (tiempo de validación <5s, capacidad 10K+ piezas, uptime 99.5%) y de negocio (reducción 40% errores logísticos, ROI estimado) dentro del README?
>
> ## User Decisions
>
> 1. README con toda la technical specification - todo estará almacenado ahí
> 2. Roadmap por valor de negocio - MVP para mostrar a inversores
> 3. README en español - código, comentarios y variables en inglés

**Resumen de la Respuesta/Acción:**
Creación del README.md como Single Source of Truth técnico con 8 secciones: arquitectura completa, stack tecnológico (React+Three.js/FastAPI+rhino3dm/PostgreSQL/LangGraph), modelo de datos, roadmap priorizado por valor de negocio (P0-MVP hasta P2-Enterprise), y user personas. Actualización de productContext.md enfocando en Oficina Técnica y Digital Twin con validación ISO-19650. Registro de decisión #013 justificando enfoque Architecture & Systems y README centralizado. 5 preguntas técnicas bloqueantes sobre monorepo, storage pesado, async processing, auth, y testing.

---

## 013 - Definición de Metodología y Fases del Proyecto
**Fecha:** 2026-01-27 10:15

**Prompt Original:**
> # Prompt: Definición de Fases del Proyecto y Reglas de Contención
> 
> **Role:** Actúa como **Project Manager y Guardián de la Metodología**.
> 
> **Contexto:**
> Vamos a desarrollar el proyecto "Sagrada Familia Parts Manager" (SF-PM). Para asegurar el éxito y evitar "alucinaciones" prematuras de código, vamos a establecer una estructura de fases estricta inspirada en metodologías de ingeniería de sistemas.
> 
> **Objetivo:**
> Actualizar el **Memory Bank** (específicamente `productContext.md`) para definir las Fases del Proyecto y las Reglas de Ejecución.
> 
> **Instrucciones para el Memory Bank (`productContext.md`):**
> 
> 1.  **Define la Estructura de Fases Oficial:**
>    Añade una sección llamada `## Estructura de Fases del Proyecto` con el siguiente contenido:
>    * **FASE 1: Análisis y Estrategia.** (Problema, Visión, Propuesta de Valor).
>    * **FASE 2: Definición del Software (PRD).** (User Personas, Alcance MVP, Stack Tecnológico conceptual).
>    * **FASE 3: Modelo de Negocio/Servicio.** (Lean Canvas adaptado a Enterprise/Oficina Técnica).
>    * **FASE 4: Casos de Uso Críticos.** (Diagramas de flujo y secuencia para Ingesta, Visualización y Auditoría).
>    * **FASE 5: Modelo de Datos.** (Esquema Entidad-Relación, Tablas SQL y Estructura JSONB).
>    * **FASE 6: Arquitectura de Alto Nivel.** (Diagrama de componentes, patrones de comunicación).
>    * **FASE 7: Diseño en Profundidad (C4).** (Foco en el "Librarian Agent" y el motor de validación).
> 
> 2.  **Establece la "Regla de Oro de Fases":**
>    Añade una sección `## Reglas de Ejecución` con la siguiente directiva:
>    > "El LLM tiene terminantemente PROHIBIDO generar contenido, código o decisiones arquitectónicas que pertenezcan a una fase futura a la actual. Solo se puede trabajar en la FASE ACTIVA designada por el usuario. Si el usuario pide algo de una fase futura, el LLM debe rechazarlo y sugerir volver a la fase actual." 
> 
> 3.  **Actualiza el Log:**
>    Añade una entrada en `prompts.md` registrando este prompt como "Definición de Metodología y Fases", tal y como se refleja en el protocolo agents.md
> 
> **Output esperado:**
> Confirma que las fases y reglas han sido grabadas en la memoria del proyecto.

**Resumen de la Respuesta/Acción:**
Actualización de `productContext.md` con estructura de 7 fases del proyecto SF-PM (Análisis y Estrategia → PRD → Modelo de Negocio → Casos de Uso → Modelo de Datos → Arquitectura Alto Nivel → Diseño Profundidad C4). Implementación de "Regla de Oro" que prohíbe al LLM trabajar en fases futuras sin aprobación explícita del usuario, con ejemplos de aplicación y mecanismo de cambio de fase. Definición del estado actual (FASE 2 en progreso) y bloqueadores para avanzar. Registro del prompt #012 en prompts.md siguiendo protocolo AGENTS.md.

---

## 014 - Generación de README Maestro (Fases 1 y 2)
**Fecha:** 2026-01-27 11:30

**Prompt Original:**
> # Prompt: Ejecución Fases 1 y 2 - Generación del README Maestro
> 
> **Role:** Actúa como **Lead Product Manager**.
> 
> **Estado del Proyecto:**
> * **Fase Activa:** FASE 1 (Análisis) y FASE 2 (Definición).
> * **Restricción:** No avanzar a Fase 3 ni posteriores.
> 
> **Objetivo:**
> Crear el documento maestro `README.md` que consolide la visión estratégica y los requisitos del producto "Sagrada Familia Parts Manager".
> 
> **Instrucciones:**
> 
> 1.  **Actualización de Contexto:**
>    * En `productContext.md`, asegura que el "Current Project Focus" sea SF-PM.
>    * En `prompts.md`, registra este prompt como "Generación de README (Fases 1 y 2)".
> 
> 2.  **Generación de Contenido (`README.md`):**
>    Crea el archivo `README.md` en la raíz. Debe contener **EXCLUSIVAMENTE** lo siguiente:
> 
>    * **Encabezado:** Nombre del proyecto y Estado ("Fase 2: Definición").
>    * **Sección FASE 1 (Estrategia):**
>        * **El Problema:** La desconexión entre el modelo paramétrico (Rhino) y la logística física en una obra de siglos de duración.
>        * **La Solución:** Un "Gemelo Digital Activo" que valida y traza cada bloque.
>        * **Propuesta de Valor:** Integridad ISO-19650, Reducción de rechazos en taller, Visualización democrática.
>    * **Sección FASE 2 (PRD):**
>        * **User Personas:**
>            * *El Arquitecto:* Necesita validación inmediata.
>            * *El Bibliotecario (OT):* Necesita higiene de datos automática.
>            * *El Gestor de Piedra:* Necesita control visual de stock.
>        * **El Agente "The Librarian":** Descripción funcional (no técnica) de cómo intercepta, valida y acepta/rechaza archivos.
>        * **Feature Map (MVP):** Ingesta, Validación Activa, Visor Web, Dashboard.
>        * **Stack Tecnológico:** React, Three.js, FastAPI, Supabase, LangGraph, Rhino3dm.
> 
> 3.  **Restricciones Negativas (Critical):**
>    * **NO** incluyas diagramas de base de datos (Fase 5).
>    * **NO** incluyas estructura de carpetas ni comandos de instalación (Fase 6).
>    * **NO** generes código.
> 
> **Output esperado:**
> El contenido del `README.md` listo para ser guardado.

**Resumen de la Respuesta/Acción:**
Creación del README.md maestro con contenido exclusivo de FASE 1 (problema Data Gravity, solución Digital Twin Activo, propuesta de valor ISO-19650) y FASE 2 (user personas arquitecto/bibliotecario/gestor piedra, descripción funcional The Librarian, feature map MVP, stack conceptual). Respeto estricto de restricciones: sin esquemas de base de datos (Fase 5), sin estructura de carpetas (Fase 6), sin código. Registro de prompt #013 en prompts.md.

---

## 015 - Completación FASE 2: Wireframes, Roadmap y User Stories
**Fecha:** 2026-01-27 12:45

**Prompt Original:**
> # Contexto: Completar FASE 2 con entregables finales
> 
> Usuario solicitó completar FASE 2 (Definición del Software - PRD) respondiendo preguntas metodológicas:
> 1. Wireframes: ASCII Art + Descripción textual
> 2. Estados: Default + Empty State
> 3. Prioridad features: Por Dependencias Técnicas (P0.1 Upload → P0.2 Validación → ... → P0.6 Visor 3D)
> 4. Criterios aceptación: Performance + UX + Data Integrity
> 5. Granularidad: Happy Path + Error principal (12-18 user stories)
> 6. Formato: Checklist Simple
> 
> **Objetivo:**
> Añadir al README.md las 3 secciones finales de FASE 2:
> - Wireframes Conceptuales (Dashboard, Upload, Visor 3D con estados Default + Empty)
> - Roadmap Detallado (6 features MVP con criterios completos: Performance, UX, Data Integrity)
> - User Stories (14 escenarios: happy paths + error paths con formato checklist)

**Resumen de la Respuesta/Acción:**
Actualización completa del README.md con: (1) Wireframes ASCII de 3 interfaces principales (Dashboard con filtros/stats/tabla, Upload con drag-drop/progreso/resultados, Visor 3D con canvas/controles/info) mostrando estados default y empty; (2) Roadmap detallado de 6 features MVP priorizadas por dependencias (P0.1 Upload → P0.6 Visor3D) con criterios triple (Performance: tiempos/capacidad, UX: feedback/navegación, Data Integrity: validación/trazabilidad); (3) 14 User Stories formato Given/When/Then con checklists de aceptación (US-001 a US-014 cubriendo happy paths upload/dashboard/visor/auth y error paths validación/permisos/credenciales). FASE 2 completada al 100%.

---

## 016 - FASE 3: Modelo de Servicio (Lean Canvas Adaptado)
**Fecha:** 2026-01-27 13:15

**Prompt Original:**
> # Prompt: FASE 3 - Modelo de Servicio (Lean Canvas Adaptado)
> 
> **Role:** Actúa como **Strategic Product Consultant** especializado en soluciones Enterprise y Transformación Digital.
> 
> **Contexto:**
> Estamos desarrollando "Sagrada Familia Parts Manager" (SF-PM).
> * **Estado Actual:** Hemos definido la Estrategia (Fase 1) y el Producto (Fase 2) en el `README.md`.
> * **Objetivo de la Sesión:** Definir la viabilidad operativa y el modelo de valor del proyecto. Entramos en la **FASE 3**.
> 
> **Instrucción Principal:**
> Genera el contenido de la **FASE 3: Modelo de Servicio (Lean Canvas)** y añádelo al archivo `README.md`.
> 
> **Requisitos del Contenido (Lean Canvas Adaptado a Enterprise):**
> Genera una tabla Markdown (formato estándar de Lean Canvas) adaptando los conceptos de negocio a una **herramienta interna de gestión patrimonial**:
> 
> 1.  **Problema (Pain Points):** Desconexión Rhino-Físico, pérdida de trazabilidad, costes por errores de corte (piedra desperdiciada), "basura" digital en servidores.
> 2.  **Segmentos de Cliente (Usuarios Internos):** Oficina Técnica (Arquitectos), Taller de Canteros (Logística), Dirección de Obra.
> 3.  **Propuesta de Valor Única:** El concepto de "Gatekeeper Activo" (Validación ISO-19650 automatizada) + Trazabilidad Inmutable. "Confianza total en el dato".
> 4.  **Solución:** Agente "The Librarian" (LangGraph), Visor Web Ligero (Three.js), Base de Datos Centralizada (Supabase).
> 5.  **Canales (Despliegue):** Intranet de la OT, Tablets rugerizadas en obra/taller.
> 6.  **Flujo de Ingresos (ROI Operativo):** *No hay ventas.* El valor es: Reducción de errores de fabricación (ahorro directo en material noble), reducción de horas de revisión manual (BIM Manager), velocidad de localización de piezas.
> 7.  **Estructura de Costes:** Desarrollo (TFM), Infraestructura Cloud (S3/DB), Mantenimiento de Modelos.
> 8.  **Métricas Clave (KPIs):** Tasa de rechazo de archivos (calidad de entrada), Tiempo medio de localización de una pieza, % de piezas trazadas correctamente.
> 9.  **Ventaja Injusta:** Acceso a datos reales históricos, conocimiento profundo del flujo de trabajo de la Sagrada Familia.
> 
> **Acciones de Ejecución:**
> 
> 1.  **Actualización de Memoria:**
>    * Registra en `prompts.md` la ejecución de "Fase 3: Modelo de Servicio".
>    * No es necesario modificar `productContext.md` si el foco sigue siendo el mismo.
> 
> 2.  **Edición del `README.md`:**
>    * Añade la sección `## FASE 3: Modelo de Servicio (Lean Canvas)` a continuación de la Fase 2.
>    * Inserta la tabla detallada.
> 
> **Restricciones (Regla de Oro):**
> * **NO** avances a la Fase 4 (Casos de uso/Diagramas).
> * **NO** definas tablas de base de datos (Fase 5).
> * Mantente estrictamente en la definición estratégica del modelo de servicio.
> 
> **Output esperado:**
> Confirma la actualización y muestra el contenido generado para la Fase 3 en el README.

**Resumen de la Respuesta/Acción:**
Actualización del README.md con FASE 3 completa: Lean Canvas adaptado a herramienta enterprise con 9 bloques (Problema: desconexión Rhino-físico/pérdida trazabilidad/costes errores; Segmentos: OT/Talleres/Dirección; Propuesta Valor: Gatekeeper Activo + trazabilidad inmutable; Solución: Librarian/Visor3D/DB centralizada; Canales: Intranet/tablets; ROI Operativo: €150k ahorro año 1 vs €60k costes; Estructura Costes: €18,660/año operativo; KPIs: tasa rechazo/tiempo localización/uptime; Ventaja: acceso datos históricos + expertise híbrido). Añadida estrategia escalabilidad 3 fases (MVP→Consolidación→Multi-proyecto) y tabla riesgos/mitigaciones. Registro prompt #015 en prompts.md. FASE 3 completada respetando restricciones (no Fase 4/5).

---

## 017 - FASE 4: Casos de Uso y Arquitectura de Flujos
**Fecha:** 2026-01-28 14:20

**Prompt Original:**
> # Prompt: FASE 4 - Modelado y Priorización de Casos de Uso (Basado en README)
> 
> **Role:** Actúa como **Lead Systems Architect** y **Product Owner** técnico.
> 
> **Contexto:**
> Estamos en la **FASE 4: Casos de Uso**.
> Tienes disponible en el `README.md` la definición exacta de las **14 User Stories (US-001 a US-014)** aprobadas en el PRD.
> No debes inventar funcionalidades nuevas. Tu trabajo es **modelar técnicamente** cómo se ejecutan esos flujos definidos, agrupándolos en "Épicas" o Casos de Uso Maestros.
> 
> **Objetivo de la Sesión:**
> Traducir las User Stories textuales en **Diagramas de Arquitectura (Mermaid)** y establecer el **Orden de Implementación**.
> 
> **Instrucciones de Ejecución:**
> 
> 1.  **Agrupación Lógica (Mapping):**
>    Agrupa las User Stories del `README.md` en **3 Flujos Críticos de Sistema** (Épicas):
>    * **CU-01: Ingesta y Validación (The Gatekeeper):** Agrupa US-001, US-002, US-003, US-004.
>    * **CU-02: Gestión y Visualización (The Viewer):** Agrupa US-005, US-006, US-010, US-011.
>    * **CU-03: Trazabilidad y Operativa (The Workflow):** Agrupa US-007, US-008, US-009, US-012.
> 
> 2.  **Análisis de Dependencias (Critical Path):**
>    * Analiza: ¿Qué datos necesita el CU-02 para funcionar? (Respuesta: Los metadatos creados en CU-01).
>    * Analiza: ¿Qué necesita el CU-03? (Respuesta: El estado base definido en CU-01 y visualizado en CU-02).
>    * Establece el orden de prioridad: **P0 (Bloqueante)** vs **P1 (Dependiente)**.
> 
> 3.  **Generación de Contenido para `README.md`:**
>    Añade la sección **FASE 4: Casos de Uso y Arquitectura de Flujos** al final del documento maestro. Para cada CU, incluye:
>    * **Título y Prioridad:** (ej: `### CU-01: Ingesta y Validación (P0 - Critical Core)`)
>    * **User Stories Cubiertas:** Lista explícitamente qué US del PRD cubre este flujo.
>    * **Diagrama de Flujo (Mermaid `flowchart TD`):** Muestra la lógica de decisión (ej: Si Validación ISO falla -> Informe de Error).
>    * **Diagrama de Secuencia (Mermaid `sequenceDiagram`):** Muestra los mensajes técnicos entre:
>        * `Frontend (React)`
>        * `API (FastAPI)`
>        * `Agent (The Librarian)`
>        * `DB (Supabase)`
>        * `Storage (S3)`
> 
> **Acciones de Memoria:**
> * Registra en `prompts.md` la ejecución de "Fase 4: Casos de Uso".
> 
> **Restricciones:**
> * Usa estrictamente los componentes del Stack definido.
> * Los diagramas de secuencia deben ser técnicos (ej: `API -> Agent: validate_iso_19650(filename)`).
> 
> **Output esperado:**
> Confirma la actualización y muestra el contenido markdown completo generado para la FASE 4 en el `README.md`.

**Resumen de la Respuesta/Acción:**
Actualización README.md con FASE 4: 3 Casos de Uso Maestros agrupando 14 User Stories. CU-01 Ingesta/Validación (P0): US-001/002/003/004 con flowchart decisión validación + sequence diagram Frontend→API→Librarian→DB→S3. CU-02 Gestión/Visualización (P1): US-005/006/010/011 con flowchart filtrado/rendering + sequence diagram carga Dashboard/Visor3D. CU-03 Trazabilidad/Operativa (P1): US-007/008/009/012/013/014 con flowchart RBAC/Event Sourcing + sequence diagram update estado/login. Análisis dependencias críticas (CU-02/03 requieren datos CU-01). Diagramas Mermaid técnicos con nombres de métodos API reales. Registro prompt #016 en prompts.md. FASE 4 completada sin avanzar a Fase 5 (modelo datos).

---

## 018 - FASE 5: Modelo de Datos (Esquema SQL & Supabase)
**Fecha:** 2026-01-28 14:45

**Prompt Original:**
> # Prompt: FASE 5 - Modelo de Datos (Esquema SQL & Supabase)
> 
> **Role:** Actúa como **Lead Database Architect** experto en PostgreSQL, Supabase y sistemas híbridos (Relacional + NoSQL).
> 
> **Contexto:**
> Entramos en la **FASE 5: Modelo de Datos**.
> Ya tenemos definidos los Casos de Uso (Ingesta, Visualización, Trazabilidad) en el `README.md`.
> Ahora debemos diseñar la estructura de base de datos que soportará el sistema "Sagrada Familia Parts Manager" (SF-PM).
> 
> **Objetivo de la Sesión:**
> Diseñar el esquema de base de datos para **Supabase (PostgreSQL)**, priorizando la integridad de datos (Trazabilidad) y la flexibilidad de metadatos (Rhino).
> 
> **Instrucciones de Ejecución:**
> 
> 1.  **Definición de Entidades Core:**
>    Define las tablas necesarias. Sugerencia de estructura base (puedes mejorarla):
>    * **`blocks` (Piezas):** Tabla maestra. UUID, Código ISO, Estado, Referencias a geometría.
>    * **`zones` (Contexto):** Para organizar (ej: Torre de María, Nivel 15).
>    * **`events` (Audit Log):** CRÍTICO. Tabla inmutable (append-only) para el Event Sourcing (Quién cambió qué y cuándo).
>    * **`users` / `profiles`:** Gestión de roles (vinculado a Supabase Auth).
> 
> 2.  **Estrategia Híbrida (JSONB):**
>    * Explica cómo usaremos columnas `JSONB` para almacenar los metadatos flexibles que extraemos de Rhino (User Text, Propiedades Físicas) sin necesidad de migrar el esquema cada vez que un arquitecto añade un atributo nuevo.
> 
> 3.  **Generación de Contenido para `README.md`:**
>    Añade la sección **FASE 5: Modelo de Datos** al documento maestro con:
>    * **Diagrama ER (Mermaid `erDiagram`):** Visualización de tablas y relaciones.
>    * **Diccionario de Datos:** Tabla descriptiva de las tablas principales y sus campos clave (ej: `status` como ENUM).
>    * **Políticas de Seguridad (RLS - Row Level Security):** Define conceptualmente quién puede leer/escribir en cada tabla (ej: *Taller solo lectura en `blocks`, escritura en `status`*).
> 
> **Acciones de Memoria:**
> * Registra en `prompts.md` la ejecución de "Fase 5: Modelo de Datos".
> 
> **Restricciones:**
> * Usa tipos de datos de PostgreSQL (uuid, jsonb, timestamptz).
> * Mantén el esquema simple pero robusto (3NF donde aplique, JSONB para flexibilidad).
> * Asegura que el diseño soporta la "Trazabilidad Inmutable" (no borrar registros, solo archivar o añadir eventos).
> 
> **Output esperado:**
> Confirma la actualización y muestra el contenido markdown completo generado para la FASE 5 en el `README.md`.

**Resumen de la Respuesta/Acción:**
Actualización README.md con FASE 5 completa: Esquema PostgreSQL/Supabase con 8 tablas (profiles, zones, blocks, events, attachments, workshops, notifications, audit_logs). Diagrama ER Mermaid mostrando relaciones (blocks 1:N events, profiles 1:N blocks/events, zones 1:N blocks, workshops 1:N blocks). Estrategia híbrida: JSONB para rhino_metadata (propiedades físicas, user_text, geometry_info) evitando migraciones constantes. Diccionario datos detallado: 8 tablas con tipos PostgreSQL (uuid, text, jsonb, timestamptz, ENUM status/role). Políticas RLS conceptuales por rol (Arquitecto: write blocks, BIM Manager: update status, Taller: read-only + update assigned, Dirección: read-only all). Índices optimización (GIN jsonb, B-tree status/zone). Triggers audit automático. Registro prompt #017 en prompts.md. FASE 5 completada respetando restricciones (no Fase 6 arquitectura).

---

## 019 - FASE 6: Arquitectura de Alto Nivel (Diseño de Sistemas)
**Fecha:** 2026-01-28 15:10

**Prompt Original:**
> # Prompt: FASE 6 - Arquitectura de Alto Nivel (Diseño de Sistemas)
> 
> **Role:** Actúa como **Senior Software Architect** experto en sistemas distribuidos, Cloud-Native y patrones de diseño modernos.
> 
> **Contexto:**
> Entramos en la **FASE 6: Arquitectura de Alto Nivel**.
> Ya tenemos definidos el Producto (Fase 2), los Casos de Uso (Fase 4) y el Modelo de Datos (Fase 5) en el `README.md`.
> El sistema "Sagrada Familia Parts Manager" (SF-PM) tiene componentes claros:
> * Frontend SPA (React + Three.js)
> * Backend API (FastAPI)
> * Base de Datos & Auth (Supabase)
> * Agente de Validación (LangGraph + Rhino3dm)
> * Almacenamiento de Archivos (S3)
> 
> **Objetivo de la Sesión:**
> Definir la arquitectura técnica global que orquestará estos componentes, asegurando escalabilidad, desacoplamiento y rendimiento (especialmente para la validación asíncrona de archivos pesados).
> 
> **Instrucciones de Ejecución:**
> 
> 1.  **Definición de Componentes y Responsabilidades:**
>    * Describe cada bloque del sistema y su función única.
>    * **Decisión Clave:** ¿Cómo se comunica la API con el Agente de Validación? Sugerencia: Patrón asíncrono (Event-Driven) para no bloquear al usuario mientras se procesa un archivo de 500MB.
> 
> 2.  **Diagrama de Arquitectura (Mermaid):**
>    * Genera un diagrama `graph TD` o `C4 Container` que muestre:
>        * **Client:** Browser (React App).
>        * **API Gateway / Backend:** FastAPI.
>        * **Data Layer:** Supabase (Auth, DB, Realtime).
>        * **Worker / Agent Layer:** El servicio de validación (The Librarian) ejecutándose en segundo plano (pueden ser Celery Workers o un servicio separado).
>        * **Storage:** Buckets S3 (Quarantine vs Clean).
> 
> 3.  **Flujos de Comunicación:**
>    * Explica cómo fluyen los datos en el caso crítico de "Ingesta":
>        1. Upload directo a S3 (Presigned URL) para velocidad.
>        2. Webhook/Evento dispara al Agente.
>        3. Agente procesa y actualiza DB.
>        4. Frontend recibe notificación vía WebSocket (Supabase Realtime).
> 
> 4.  **Generación de Contenido para `README.md`:**
>    Añade la sección **FASE 6: Arquitectura de Alto Nivel** al documento maestro.
> 
> **Acciones de Memoria:**
> * Registra en `prompts.md` la ejecución de "Fase 6: Arquitectura de Sistemas".
> 
> **Restricciones:**
> * Mantén la arquitectura realista para un TFM (no sobre-ingeniería con Kubernetes si no es necesario).
> * Usa servicios gestionados donde sea posible (Supabase) para simplificar la infraestructura.
> 
> **Output esperado:**
> Confirma la actualización y muestra el contenido markdown completo generado para la FASE 6 en el `README.md`.

**Resumen de la Respuesta/Acción:**
Actualización README.md con FASE 6 completa: Arquitectura Cloud-Native con 6 capas (Client Layer React/Three.js, API Layer FastAPI, Worker Layer Celery+LangGraph, Data Layer Supabase PostgreSQL+Auth+Realtime, Storage Layer S3 buckets quarantine/raw/processed, External Services OpenAI). Diagrama C4 Container con comunicación async (API→Redis Queue→Celery Workers→S3→DB→WebSocket→Frontend). Patrones arquitectónicos: Event-Driven para uploads pesados, Presigned URLs upload directo, Background Jobs con Celery/Redis, Event Sourcing inmutable, WebSockets notificaciones real-time. Flujo crítico Ingesta documentado: 8 pasos desde presigned URL hasta WebSocket notification. Decisiones técnicas: Railway deploy FastAPI, Vercel frontend, Supabase managed services, S3-compatible storage. Diagramas deployment e infrastructure. Registro prompt #018 en prompts.md. FASE 6 completada sin avanzar a Fase 7 (C4 profundo).

---


## 020 - FASE 7: Diseño en Profundidad C4 del Agente "The Librarian"
**Fecha:** 2026-01-28 10:35
**Prompt Original:**
> # Prompt: FASE 7 - Diseño en Profundidad C4 (The Librarian Agent)
> 
> **Role:** Actúa como **Lead AI Engineer** y Arquitecto de Software especializado en el modelo C4 y orquestación de agentes (LangGraph).
> 
> **Contexto:**
> Entramos en la **FASE 7: Diseño en Profundidad**.
> El componente más crítico y diferenciador de "Sagrada Familia Parts Manager" es el **Agente de Validación Activa ("The Librarian")**.
> En la Fase 6 definimos que es un servicio asíncrono. Ahora debemos diseñar su arquitectura interna.
> 
> **Objetivo de la Sesión:**
> Generar el **Diagrama C4 de Nivel 3 (Component View)** específico para el Agente "The Librarian". Necesitamos entender cómo procesa un archivo `.3dm` paso a paso sin "alucinar" y con robustez industrial.
> 
> **Instrucciones de Ejecución:**
> 
> 1.  **Definición de Componentes Internos del Agente:**
>    Desglosa "The Librarian" en sub-componentes lógicos. Ejemplo:
>    * **State Manager (LangGraph):** Mantiene el estado de la validación (Pendiente -> Validando Sintaxis -> Validando Geometría...).
>    * **Syntax Validator:** Motor de Reglas (Regex) para ISO-19650.
>    * **Geometry Extractor:** Wrapper de `rhino3dm` que abre el archivo y extrae metadatos.
>    * **Semantic Validator (LLM):** Cliente que envía metadatos a GPT-4 para comprobaciones de sentido común ("¿Es normal que este bloque pese 5 toneladas?").
>    * **Report Generator:** Compila los errores en un JSON/PDF amigable.
> 
> 2.  **Flujo de Datos Interno:**
>    Explica cómo pasa el dato de un componente a otro.
>    * *Ejemplo:* Syntax Validator (OK) -> Geometry Extractor (Extract) -> Semantic Validator (Check) -> DB Commit.
> 
> 3.  **Generación de Contenido para `README.md`:**
>    Añade la sección **FASE 7: Diseño Detallado del Agente (C4 Level 3)** al documento maestro con:
>    * **Descripción de Componentes:** Tabla con responsabilidad de cada módulo interno.
>    * **Diagrama C4 (Mermaid `C4Component` o `classDiagram` adaptado):** Muestra las conexiones internas y las salidas hacia Supabase/S3.
>    * **Grafo de Estado (Mermaid `stateDiagram-v2`):** Visualización de los nodos de LangGraph (Inicio -> CheckISO -> CheckGeo -> CheckAI -> Fin).
> 
> **Acciones de Memoria:**
> * Registra en `prompts.md` la ejecución de "Fase 7: Diseño Detallado C4".
> 
> **Restricciones:**
> * Céntrate exclusivamente en el Agente. No rediseñes el Frontend ni la API.
> * Usa terminología de LangGraph (Nodos, Edges, State).
> 
> **Output esperado:**
> Confirma la actualización y muestra el contenido markdown completo generado para la FASE 7 en el `README.md`.

**Resumen de la Respuesta/Acción:**
Diseño arquitectónico C4 Level 3 del Agente "The Librarian" (validación inteligente .3dm). Componentes internos: StateManager (LangGraph orchestrator), SyntaxValidator (ISO-19650 regex), GeometryExtractor (rhino3dm parser), SemanticValidator (GPT-4 client), ReportGenerator (validation results), ErrorHandler (retry/fallback logic). Diagrama C4 Component con 6 módulos internos + conexiones a DB/S3/OpenAI. Grafo de estado LangGraph con 8 nodos: START→ValidateNomenclature→ExtractGeometry→ValidateGeometry→ClassifyTipologia→EnrichMetadata→GenerateReport→END (con edges condicionales success/error). Tabla de responsabilidades por componente. Flujo de datos paso a paso desde ingesta hasta commit DB. Inserción de FASE 7 en README.md tras FASE 6. Actualización prompts.md (#019).

---

## 021 - FASE 8: Planificación Técnica y Estructura de Repositorio
**Fecha:** 2026-01-28 17:20
**Prompt Original:**
> # Prompt: FASE 8 - Planificación Técnica y Estructura de Repositorio
> 
> **Role:** Actúa como **Tech Lead** y **DevOps Engineer**.
> 
> **Contexto:**
> Hemos completado la documentación teórica en la carpeta `docs/`.
> El proyecto "Sagrada Familia Parts Manager" está listo para comenzar la implementación.
> Necesitamos definir la estructura física del código y el plan de trabajo secuencial.
> 
> **Objetivo:**
> 1.  Definir la **Estructura de Directorios** del repositorio (Monorepo).
> 2.  Crear el **Roadmap de Implementación** (Backlog técnico).
> 3.  Preparar el entorno para el "Primer Commit".
> 
> **Instrucciones de Ejecución:**
> 
> 1.  **Definición de Estructura de Carpetas:**
>    Propón el árbol de directorios ideal para este stack (FastAPI + React + Supabase + LangGraph).
>    * Debe incluir carpetas para `backend/`, `frontend/`, `agent/` y `shared/` (si aplica).
>    * Incluye archivos de configuración clave (`docker-compose.yml`, `.gitignore`, `pyproject.toml`, `package.json`).
>    * *Nota: No generes el código de los archivos aún, solo la estructura del árbol.*
> 
> 2.  **Creación del Roadmap (`docs/08-roadmap.md`):**
>    Crea un nuevo archivo de documentación llamado `docs/08-roadmap.md`.
>    Desglosa el desarrollo en **4 Sprints** lógicos:
>    * **Sprint 0: Walking Skeleton.** (Setup de entorno, Docker, conexión Front-Back-DB con "Hello World").
>    * **Sprint 1: The Core (Ingesta).** (Endpoint upload, Validación básica, Guardado en Supabase).
>    * **Sprint 2: The Librarian (Agente).** (Integración de LangGraph, lógica de validación real).
>    * **Sprint 3: The Viewer (Visualización).** (Integración Three.js, carga de GLB).
> 
> 3.  **Actualización de Memoria:**
>    * Actualiza `productContext.md`: Cambia el estado del proyecto a **"Phase: Execution & Development"**.
>    * Actualiza `prompts.md`: Registra "Fase 8: Planificación Técnica".
> 
> **Output esperado:**
> 1.  El bloque de código con el árbol de directorios propuesto.
> 2.  La confirmación de que se ha creado `docs/08-roadmap.md`.
> 3.  Una pregunta final: "¿Quieres que genere los archivos de configuración iniciales (Docker/Git) ahora?"

**Resumen de la Respuesta/Acción:**
Definiré la estructura completa del monorepo (backend FastAPI + frontend React + agente LangGraph + shared types), crearé el roadmap técnico con 4 sprints (Walking Skeleton → Core Ingestion → Librarian Agent → 3D Viewer), y actualizaré el estado del proyecto a fase de ejecución en el Memory Bank.

---
